{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "______________\n",
    "\n",
    "## EWR TOOL beta 0.0.3\n",
    "______________\n",
    "**For issues relating to the script, a tutorial, or to provide feedback please contact Martin Job at martin.job@mdba.gov.au or Joel Bailey at joel.bailey@mdba.gov.au**\n",
    "\n",
    "Please consult the user manual prior to running the script.\n",
    "______________________________\n",
    "\n",
    "The EWR tool is used for evaluating Environmental Watering Requirement (EWR) success for given flow timeseries. This tool has two distinct uses:\n",
    "1. Operational: Tracking EWR success at gauges of interest in real time (Has not been updated since 0.0.1 - unstable)\n",
    "2. Planning: Comparing EWR success between scenarios (i.e. model runs)\n",
    "\n",
    "The outputs of the program:\n",
    "- Standard EWR output (results summary page)\n",
    "- Yearly results summary for each location\n",
    "\n",
    "Catchments this tool is currently compatable with:\n",
    "- NSW Murray Lower-Darling\n",
    "- Murrumbidgee\n",
    "- Most of the Gwydir\n",
    "- Most of the Lachlan\n",
    "- Most of the Macquarie - Castlereagh\n",
    "________________________________    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# If running in jupyter lab, leave uncommented, if running in jupyter notebook, remove comments\n",
    "# %%javascript\n",
    "# IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612478355320
    }
   },
   "outputs": [],
   "source": [
    "# If running in jupyter lab, leave uncommented, if running in jupyter notebook, remove comments\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "gather": {
     "logged": 1612487722807
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import dashboard\n",
    "import data_inputs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1612491508399
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dashboard.ewr_dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load in the real time/real world results:**\n",
    "\n",
    "Once you have clicked run program in the above dashboard under the 'Real-time EWRs' tab, you will be able to run the below cell to bring the yearly results and results summary into the below variables into the notebook. From here you will be able to perform further testing and analysis on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    realTime_summary = dashboard.results_summary_rt\n",
    "    realTime = dashboard.raw_data_rt\n",
    "    print('Real-time results loaded into the notebook')\n",
    "except AttributeError:\n",
    "    print(\"Run the 'Real-time EWRs' program and try again\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load in the scenario testing results:**\n",
    "\n",
    "Once you have clicked run program in the above dashboard under the 'Scenario testing' tab, you will be able to run the below cell to bring the yearly results and results summary into the below variables into the notebook. From here you will be able to perform further testing and analysis on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  \n",
    "    scenarioTest_summary = dashboard.data_summary_s\n",
    "    scenarioTest = dashboard.raw_data_s\n",
    "    print('Scenario testing results loaded into the notebook')\n",
    "except AttributeError:\n",
    "    print(\"Run the 'Scenario testing' program and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Checking the EWRs in the database**\n",
    "\n",
    "The program accesses the ewrs from a master table, and filters out the ewrs not yet readable by a machine. Running the below cells will show you the ewrs available for evaluation (the goodEwrs dataframe), and the seven groups of ewrs not yet readable by this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_inputs\n",
    "goodEwrs, seeNotesEwrs, undefinedEwrs, noThresh_df, noDurationEwrs, DSFewrs = data_inputs.get_ewr_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(goodEwrs))\n",
    "goodEwrs.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seeNotesEwrs))\n",
    "seeNotesEwrs.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(undefinedEwrs))\n",
    "undefinedEwrs.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(noThresh_df))\n",
    "noThresh_df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(noDurationEwrs))\n",
    "noDurationEwrs.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DSFewrs))\n",
    "DSFewrs.style"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
