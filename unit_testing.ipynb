{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d4cebd",
   "metadata": {},
   "source": [
    "## Unit testing the EWR tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea824875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "from pandas._testing import assert_frame_equal\n",
    "from datetime import datetime, date\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from mdba_gauge_getter import gauge_getter\n",
    "from py_ewr import dashboard, data_inputs,scenario_handling, observed_handling, evaluate_EWRs, summarise_results\n",
    "\n",
    "BASE_PATH = Path(os.path.abspath('')).resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad2e47",
   "metadata": {},
   "source": [
    "### Testing function in summarise_results.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95ff3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......../tmp/ipykernel_12590/2379932420.py:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].iloc[i] = new_list\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.895s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=9 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_summarise_results(unittest.TestCase):\n",
    "    def test_sum_events(self):\n",
    "        '''\n",
    "        Series input to summarise_results function will only be made up of combination of 1's or 0's. \n",
    "        1. Test to see if function is counting occurences of 1's\n",
    "        '''\n",
    "        # Test 1\n",
    "        input_series = pd.Series(index=[1895, 1896, 1897, 1898, 1899], data=[0,1,1,1,0])\n",
    "        s = summarise_results.sum_events(input_series)\n",
    "        expected_s = 3\n",
    "        self.assertEqual(s, expected_s)\n",
    "    \n",
    "    \n",
    "    def test_get_frequency(self):\n",
    "        '''\n",
    "        Series input to get_frequency function will only be made up of combination of 1's or 0's.\n",
    "        1. Test to see if function is returning frequency of 1 occurence out of all years. \n",
    "        2. Test to see if function handles no occurence of 1's\n",
    "        '''\n",
    "        # Test 1\n",
    "        input_series = pd.Series(index=[1895, 1896, 1897, 1898, 1899], data=[0,1,1,1,0])\n",
    "        f = summarise_results.get_frequency(input_series)\n",
    "        expected_f = 60\n",
    "        self.assertEqual(f, expected_f)\n",
    "        # ----------------------------\n",
    "        # Test 2\n",
    "        input_series = pd.Series(index=[1895, 1896, 1897, 1898, 1899], data=[0,0,0,0,0])\n",
    "        f = summarise_results.get_frequency(input_series)\n",
    "        expected_f = 0\n",
    "        self.assertEqual(f, expected_f)\n",
    "\n",
    "    def test_get_average(self):\n",
    "        '''\n",
    "        Input will be a series of years and either integers or floats\n",
    "        1. Test average\n",
    "        2. Test average if all numbers in series are 0\n",
    "        '''\n",
    "        # Test 1\n",
    "        input_series = pd.Series(index=[1895, 1896, 1897, 1898, 1899], data=[100,100,50,50,0])\n",
    "        f = summarise_results.get_average(input_series)\n",
    "        expected_f = 60\n",
    "        self.assertEqual(f, expected_f)\n",
    "        # ----------------------------\n",
    "        # Test 2\n",
    "        input_series = pd.Series(index=[1895, 1896, 1897, 1898, 1899], data=[0,0,0,0,0])\n",
    "        f = summarise_results.get_average(input_series)\n",
    "        expected_f = 0\n",
    "        self.assertEqual(f, expected_f)\n",
    "        \n",
    "    def test_event_length(self):\n",
    "        '''\n",
    "        Input is a tuple containing dictionaries of events. Typical tuples contain one dictionary, however, for the EWRs that require flows to be met across multiple sites, there will be multiple event dictionaries within the tuple\n",
    "        1. Test getting the average event length over a multi site EWR\n",
    "        2. Test getting the average event length over a single site EWR\n",
    "        '''\n",
    "        # Test 1\n",
    "        events1 = {2012: [[50,50,50,100,100,100],[5,5,7.5,10,10]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: [[50,50,50,100,100,100],[5,5,7.5,10,10]]}\n",
    "        events2 = {2012: [[50,50,50,100,100,100]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: []}\n",
    "        tupled = tuple([events1, events2])\n",
    "        EWR = {}\n",
    "        EWR['VL'] = tupled\n",
    "        PU = {}\n",
    "        PU['planning unit 1'] = EWR\n",
    "        gauge = {}\n",
    "        gauge['425001'] = PU\n",
    "        scenario = {}\n",
    "        scenario['scenario 1'] = gauge\n",
    "        f = summarise_results.get_event_length(scenario['scenario 1']['425001']['planning unit 1']['VL'])\n",
    "        \n",
    "        expected_f = 5.111111111111111\n",
    "        self.assertEqual(expected_f, f)\n",
    "        #------------------------------\n",
    "        # Test 2\n",
    "        events1 = {2012: [[50,50,50,100,100,100],[5,5,7.5,10,10]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: [[50,50,50,100,100,100],[5,5,7.5,10,10]]}\n",
    "        tupled = tuple([events1])\n",
    "        EWR = {}\n",
    "        EWR['VL'] = tupled\n",
    "        PU = {}\n",
    "        PU['planning unit 1'] = EWR\n",
    "        gauge = {}\n",
    "        gauge['425001'] = PU\n",
    "        scenario = {}\n",
    "        scenario['scenario 1'] = gauge\n",
    "\n",
    "        f = summarise_results.get_event_length(scenario['scenario 1']['425001']['planning unit 1']['VL'])\n",
    "        \n",
    "        expected_f = 5.166666666666667\n",
    "        self.assertEqual(expected_f, f)        \n",
    "        \n",
    "    def test_get_threshold_days(self):\n",
    "        '''\n",
    "        Input is a tuple containing dictionaries of events. Typical tuples contain one dictionary, however, for the EWRs that require flows to be met across multiple sites, there will be multiple event dictionaries within the tuple\n",
    "        1. Test getting the total event length of multi site EWR\n",
    "        2. Test getting the total event length over a single site EWR\n",
    "        '''\n",
    "        # Test 1\n",
    "        events1 = {2012: [[50,50,50,100,100,100],[5,5,7.5,10,10]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: [[50,50,50,100,100,100],[5,5,7.5,10,10]]}\n",
    "        events2 = {2012: [[50,50,50,100,100,100]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: []}\n",
    "        tupled = tuple([events1, events2])\n",
    "        EWR = {}\n",
    "        EWR['VL'] = tupled\n",
    "        PU = {}\n",
    "        PU['planning unit 1'] = EWR\n",
    "        gauge = {}\n",
    "        gauge['425001'] = PU\n",
    "        scenario = {}\n",
    "        scenario['scenario 1'] = gauge\n",
    "        f = summarise_results.get_event_length(scenario['scenario 1']['425001']['planning unit 1']['VL'])\n",
    "        \n",
    "        expected_f = 5.111111111111111\n",
    "        self.assertEqual(expected_f, f)\n",
    "        #------------------------------\n",
    "        # Test 2\n",
    "        events1 = {2012: [[50,50,50,100,100,100],[5,5,7.5,10,10]], 2013: [[50,50,100,100],[5,5,7.5,10,10]], 2014: [[50,50,50,100,100,100],[5,5,7.5,10,10]]}\n",
    "        tupled = tuple([events1])\n",
    "        EWR = {}\n",
    "        EWR['VL'] = tupled\n",
    "        PU = {}\n",
    "        PU['planning unit 1'] = EWR\n",
    "        gauge = {}\n",
    "        gauge['425001'] = PU\n",
    "        scenario = {}\n",
    "        scenario['scenario 1'] = gauge\n",
    "\n",
    "        f = summarise_results.get_event_length(scenario['scenario 1']['425001']['planning unit 1']['VL'])\n",
    "        \n",
    "        expected_f = 5.166666666666667\n",
    "        self.assertEqual(expected_f, f)  \n",
    "        \n",
    "        \n",
    "    def test_count_exceedence(self):\n",
    "        '''\n",
    "        Input is a series with water years along the index, and a list of lists, containing integers for the data.\n",
    "        1. Test number of exceedences when there is a max interevent to be exceeded\n",
    "        2. Test the function returns 'N/A' when there is no max interevent to be checked event for this EWR\n",
    "        '''\n",
    "        # Test 1\n",
    "        index = [1895, 1896, 1897, 1898, 1899, 1900]\n",
    "        data = [[15, 30], [], [], [450, 2], [10,12], [200,10]]\n",
    "        series = pd.Series(index=index, data=data)\n",
    "\n",
    "        EWR_info = {'max_inter-event': 2}\n",
    "\n",
    "        result = summarise_results.count_exceedence(series, EWR_info)\n",
    "        expected_result = 8 # There are 8 exceedences in the above list\n",
    "        self.assertEqual(result, expected_result)\n",
    "        # ---------------------------------------\n",
    "        # Test 2\n",
    "        index = [1895, 1896, 1897, 1898, 1899, 1900]\n",
    "        data = [[15, 30], [], [], [450, 2], [10,12], [200,10]]\n",
    "        series = pd.Series(index=index, data=data)\n",
    "\n",
    "        EWR_info = {'max_inter-event': None}\n",
    "\n",
    "        result = summarise_results.count_exceedence(series, EWR_info)\n",
    "        expected_result = 'N/A' # There is no max interevent period defined so cannot return a result\n",
    "        self.assertEqual(result, expected_result)\n",
    "        \n",
    "    def test_initialise_summary_df_columns(self):\n",
    "        '''\n",
    "        Input is a dictionary of scenario EWR results for each gauge and planning unit.\n",
    "        1. Test proper initialisation of multi index columns\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Input data and send to function\n",
    "        columns = ['Event years','Frequency','Target frequency','Achievement count', 'Achievements per year', 'Event count','Events per year',\n",
    "                    'Event length','Threshold days','Inter-event exceedence count', 'Max inter event period (years)', 'No data days',\n",
    "                    'Total days']\n",
    "        df = pd.DataFrame()\n",
    "        df1 = pd.DataFrame()\n",
    "        input_dictionary = {'Scenario 1': {'Gauge 1': {'Planning unit 1': df}}, 'Scenario 2': {'Gauge 1': {'Planning unit 1': df1}}}\n",
    "\n",
    "        multi_index = summarise_results.initialise_summary_df_columns(input_dictionary)\n",
    "        # Define expected output given the above input\n",
    "        tuples = [('Scenario 1', 'Event years'),\n",
    "                  ('Scenario 1', 'Frequency'),\n",
    "                  ('Scenario 1', 'Target frequency'),\n",
    "                  ('Scenario 1', 'Achievement count'),\n",
    "                  ('Scenario 1', 'Achievements per year'),\n",
    "                  ('Scenario 1', 'Event count'),\n",
    "                  ('Scenario 1', 'Events per year'),\n",
    "                  ('Scenario 1', 'Event length'),\n",
    "                  ('Scenario 1', 'Threshold days'),\n",
    "                  ('Scenario 1', 'Inter-event exceedence count'),\n",
    "                  ('Scenario 1', 'Max inter event period (years)'),\n",
    "                  ('Scenario 1', 'No data days'),\n",
    "                  ('Scenario 1', 'Total days'),\n",
    "                  ('Scenario 2', 'Event years'),\n",
    "                  ('Scenario 2', 'Frequency'),\n",
    "                  ('Scenario 2', 'Target frequency'),\n",
    "                  ('Scenario 2', 'Achievement count'),\n",
    "                  ('Scenario 2', 'Achievements per year'),\n",
    "                  ('Scenario 2', 'Event count'),\n",
    "                  ('Scenario 2', 'Events per year'),\n",
    "                  ('Scenario 2', 'Event length'),\n",
    "                  ('Scenario 2', 'Threshold days'),\n",
    "                  ('Scenario 2', 'Inter-event exceedence count'),\n",
    "                  ('Scenario 2', 'Max inter event period (years)'),\n",
    "                  ('Scenario 2', 'No data days'),\n",
    "                  ('Scenario 2', 'Total days')]\n",
    "        expected_multi_index = pd.MultiIndex.from_tuples(tuples, names=['scenario', 'type'])\n",
    "        \n",
    "        # test result:\n",
    "        for i, tup in enumerate(expected_multi_index):\n",
    "            for index, val in enumerate(tup):\n",
    "                self.assertEqual(multi_index[i][index], val)\n",
    "                \n",
    "    def test_initialise_summary_df_rows(self):\n",
    "        '''\n",
    "        Input is a dictionary of scenario EWR results for each gauge and planning unit.\n",
    "        1. Test for expected initialisation of three layered multi index\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Setting up input data and sending to function:\n",
    "        columns = ['CF1_eventYears','CF1_numAchieved','CF1_numEvents','CF1_eventLength','CF1_totalEventDays','CF1_daysBetweenEvents','CF1_missingDays','CF1_totalPossibleDays','VF1_eventYears',\n",
    "         'VF1_numAchieved','OB-L1_S_missingDays','OB-L1_S_totalPossibleDays','OB-L1_P_eventYears','OB-L1_P_numAchieved','OB-L1_P_numEvents','OB-L1_P_eventLength']\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "        input_dictionary = {'Scenario 1': {'Gauge 1': {'Planning unit 1': df}}, 'Scenario 2': {'Gauge 1': {'Planning unit 1': df}}}\n",
    "\n",
    "        multi_index = summarise_results.initialise_summary_df_rows(input_dictionary)\n",
    "\n",
    "        # Setting up expected output:\n",
    "        tuples = [('Gauge 1', 'Planning unit 1', 'CF1'), ('Gauge 1', 'Planning unit 1', 'VF1'), ('Gauge 1', 'Planning unit 1', 'OB-L1_S'), ('Gauge 1', 'Planning unit 1', 'OB-L1_P')]\n",
    "        expected_multi_index = pd.MultiIndex.from_tuples(tuples, names=['gauge', 'planning unit', 'EWR'])\n",
    "        \n",
    "        # Test result:\n",
    "        for i, tup in enumerate(expected_multi_index):\n",
    "            for index, val in enumerate(tup):\n",
    "                self.assertEqual(multi_index[i][index], val)        \n",
    "        \n",
    "    def test_allocate(self):\n",
    "        '''\n",
    "        Input is a dataframe to save information to, the information to be saved, and the coordinates of the dataframe\n",
    "        1. Test information is being saved in the expected location in the dataframe\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Define input data and send to function:\n",
    "        tuples = [('Scenario 1', 'Event years'),\n",
    "                  ('Scenario 1', 'Frequency'),\n",
    "                  ('Scenario 2', 'No data days'),\n",
    "                  ('Scenario 2', 'Total days')]\n",
    "        multi_column = pd.MultiIndex.from_tuples(tuples, names=['scenario', 'type'])        \n",
    "        tuples = [('Gauge 1', 'Planning unit 1', 'CF1'), \n",
    "                  ('Gauge 1', 'Planning unit 1', 'VF1'), \n",
    "                  ('Gauge 1', 'Planning unit 1', 'OB-L1_S'), \n",
    "                  ('Gauge 1', 'Planning unit 1', 'OB-L1_P')]\n",
    "        multi_index = pd.MultiIndex.from_tuples(tuples, names=['gauge', 'planning unit', 'EWR'])\n",
    "        df = pd.DataFrame(index = multi_index, columns=multi_column)\n",
    "        add_this = 12\n",
    "        idx = pd.IndexSlice\n",
    "        site = 'Gauge 1'\n",
    "        PU = 'Planning unit 1'\n",
    "        EWR = 'OB-L1_S'\n",
    "        scenario = 'Scenario 2'\n",
    "        category = 'No data days'\n",
    "        result_df = summarise_results.allocate(df, add_this, idx, site, PU, EWR, scenario, category)\n",
    "        # Set expected dataframe\n",
    "        expected_df = pd.DataFrame(index = multi_index, columns=multi_column)\n",
    "        expected_df.loc[idx[[site], [PU], [EWR]], idx[scenario, category]] = 12\n",
    "        # Test result:\n",
    "        assert_frame_equal(result_df, expected_df)\n",
    "        \n",
    "    def test_summarise(self):\n",
    "        '''\n",
    "        Inputs are a dictionary containing annualised results for each Scenario>Gauge>Planning Unit>EWR and \n",
    "        a dictionary containing individual event information for each Scenario>Gauge>Planning Unit>EWR\n",
    "        1. Test each part of the function are working correctly and producing an overall expected output\n",
    "        '''\n",
    "        \n",
    "        # Test 1\n",
    "        # setting up input data and sending to function\n",
    "        df = pd.read_csv('unit_testing_files/input_for_summarise_data.csv', index_col  =0)\n",
    "        for col in df:\n",
    "            if 'daysBetweenEvents' in col:\n",
    "                for i, val in enumerate(df[col]):\n",
    "                    new = df[col].iloc[i]\n",
    "                    if new == '[]':\n",
    "                        new_list = []\n",
    "                    else:\n",
    "                        new = re.sub('\\[', '', new)\n",
    "                        new = re.sub('\\]', '', new)\n",
    "                        new = new.split(',')\n",
    "                        new_list = []\n",
    "                        for days in new:\n",
    "                            new_days = days.strip()\n",
    "                            new_days = int(new_days)\n",
    "                            new_list.append(new_days)\n",
    "\n",
    "                    df[col].iloc[i] = new_list\n",
    "        input_dict = {'Scenario 1': {'410007': {'Upper Yanco Creek': df}}}\n",
    "        input_events = {'Scenario 1': {'410007': {'Upper Yanco Creek': {'VF1': tuple([{1895: [[400]*100, [400]*50],\n",
    "                                                                               1896: [], \n",
    "                                                                               1897: [[500]*50, [400]*30], \n",
    "                                                                               1898: [], \n",
    "                                                                               1899: [], \n",
    "                                                                               1900: [[500]*345]}])}}}}\n",
    "        result = summarise_results.summarise(input_dict, input_events)\n",
    "        # Set up expected outputs and test\n",
    "        tuples = [('Scenario 1', 'Event years'),\n",
    "                  ('Scenario 1', 'Frequency'),\n",
    "                  ('Scenario 1', 'Target frequency'),\n",
    "                  ('Scenario 1', 'Achievement count'),\n",
    "                  ('Scenario 1', 'Achievements per year'),\n",
    "                  ('Scenario 1', 'Event count'),\n",
    "                  ('Scenario 1', 'Events per year'),\n",
    "                  ('Scenario 1', 'Event length'),\n",
    "                  ('Scenario 1', 'Threshold days'),\n",
    "                  ('Scenario 1', 'Inter-event exceedence count'),\n",
    "                  ('Scenario 1', 'Max inter event period (years)'),\n",
    "                  ('Scenario 1', 'No data days'),\n",
    "                  ('Scenario 1', 'Total days')]\n",
    "        multi_column = pd.MultiIndex.from_tuples(tuples, names=['scenario', 'type'])        \n",
    "        tuples = [('410007', 'Upper Yanco Creek', 'VF1')]\n",
    "        multi_index = pd.MultiIndex.from_tuples(tuples, names=['gauge', 'planning unit', 'EWR'])\n",
    "        expected_df = pd.DataFrame(index = multi_index, columns=multi_column)\n",
    "        expected_df.iloc[0]=[3, 50, str(100), 3, 0.5, 3, 0.5, 115.0, 575, 0, 0.010958904, 0, 2191]        \n",
    "        \n",
    "        assert_frame_equal(result, expected_df)\n",
    "        \n",
    "Test = test_summarise_results()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_summarise_results('test_sum_events'))\n",
    "suite.addTest(test_summarise_results('test_get_frequency'))\n",
    "suite.addTest(test_summarise_results('test_get_average'))\n",
    "suite.addTest(test_summarise_results('test_event_length'))\n",
    "suite.addTest(test_summarise_results('test_count_exceedence'))\n",
    "suite.addTest(test_summarise_results('test_initialise_summary_df_columns'))\n",
    "suite.addTest(test_summarise_results('test_initialise_summary_df_rows'))\n",
    "suite.addTest(test_summarise_results('test_allocate'))\n",
    "suite.addTest(test_summarise_results('test_summarise'))\n",
    "\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230631f5",
   "metadata": {},
   "source": [
    "### Testing functions in data_inputs.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e8e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../home/pedro/.pyenv/versions/3.8.13/lib/python3.8/unittest/case.py:633: UserWarning: Parsing '31/12/2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  method()\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 2.821s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=9 errors=0 failures=0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_data_inputs(unittest.TestCase):\n",
    "    def test_convert_max_interevent(self):\n",
    "        '''\n",
    "        1. Test max interevent is converted from years to days\n",
    "        '''\n",
    "        # Test 1\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        water_years = [2012]*365+[2013]*365+[2014]*365+[2015]*365\n",
    "        EWR_info = {'max_inter-event': 1}\n",
    "        new_max_interevent = data_inputs.convert_max_interevent(unique_water_years, water_years, EWR_info)\n",
    "        self.assertEqual(new_max_interevent, 365)\n",
    "        \n",
    "        \n",
    "    def test_gauge_to_catchment(self):\n",
    "        '''\n",
    "        1. Test gauge in Gwydir returns Gwydir\n",
    "        2. Test gauge in Namoi returns Namoi\n",
    "        '''\n",
    "        # Test 1\n",
    "        expected_catchment = 'Gwydir'\n",
    "        input_gauge = '418026'\n",
    "        catchment = data_inputs.gauge_to_catchment(input_gauge)\n",
    "        self.assertEqual(catchment, expected_catchment)\n",
    "        # Test 2\n",
    "        expected_catchment = 'Namoi'\n",
    "        input_gauge = '419049'\n",
    "        catchment = data_inputs.gauge_to_catchment(input_gauge)\n",
    "        self.assertEqual(catchment, expected_catchment)\n",
    "        \n",
    "        \n",
    "    def test_wy_to_climate(self):\n",
    "        '''\n",
    "        1. Test an array of climate categorisations are returned for each day of the input data\n",
    "        '''\n",
    "        # Setting up input data \n",
    "        data = {'418026': list(range(0,730,1)), '425012': list(range(0,1460,2))}\n",
    "        index = pd.date_range(start='1/1/2017', end='31/12/2018')\n",
    "        df = pd.DataFrame(data = data, index = index)\n",
    "        water_years = np.array([2017]*365+[2018]*365)\n",
    "        climate_daily = data_inputs.wy_to_climate(water_years, 'Gwydir', 'Standard - 1911 to 2018 climate categorisation')\n",
    "        # Setting up expected output data and the test\n",
    "        expected_climate_daily = np.array(['Dry']*365 + ['Very Dry']*365)\n",
    "        self.assertTrue(np.array_equal(climate_daily, expected_climate_daily))\n",
    "        \n",
    "        \n",
    "    def test_get_multi_gauges(self):\n",
    "        '''\n",
    "        1. Test for returning planning units and gauges where there are multi gauge EWR requirements\n",
    "        2. Test for returning the unique gauge to gauge dictionaries where there are multi gauge EWR requirements\n",
    "        '''\n",
    "        # Test 1\n",
    "        expected_multi_gauges = {'PU_0000130': {'421090': '421088', '421088': '421090'},\n",
    "                                 'PU_0000131': {'421090': '421088', '421088': '421090'},\n",
    "                                 'PU_0000132': {'421090': '421088', '421088': '421090'},\n",
    "                                 'PU_0000133': {'421090': '421088', '421088': '421090'}}\n",
    "        multi_gauges = data_inputs.get_multi_gauges('all')\n",
    "        self.assertDictEqual(expected_multi_gauges, multi_gauges)\n",
    "        #--------------------------------------------------------\n",
    "        # Test 2\n",
    "        expected_multi_gauges = {'421090': '421088', '421088': '421090'}\n",
    "        multi_gauges = data_inputs.get_multi_gauges('gauges')\n",
    "        self.assertDictEqual(expected_multi_gauges, multi_gauges)\n",
    "        \n",
    "        \n",
    "    def test_get_simultaneous_gauges(self):\n",
    "        '''\n",
    "        1. Test for returning planning units and gauges where there are simultaneous gauge EWR requirements\n",
    "        2. Test for returning the unique gauge to gauge dictionaries where there are simultaneous gauge EWR requirements\n",
    "        '''\n",
    "        # Testing the return all request\n",
    "        expected_sim_gauges = {'PU_0000131': {'421090': '421022', '421022': '421090'},\n",
    "                               'PU_0000132': {'421090': '421022', '421022': '421090'},\n",
    "                               'PU_0000133': {'421090': '421022', '421022': '421090'}}\n",
    "        sim_gauges = data_inputs.get_simultaneous_gauges('all')\n",
    "        self.assertDictEqual(expected_sim_gauges, sim_gauges)\n",
    "        #----------------------------------------------------\n",
    "        # Testing the return just gauges request\n",
    "        expected_sim_gauges = {'421090': '421022', '421022': '421090'}\n",
    "        sim_gauges = data_inputs.get_simultaneous_gauges('gauges')\n",
    "        self.assertDictEqual(expected_sim_gauges, sim_gauges)\n",
    "        \n",
    "        \n",
    "    def test_get_climate_cats(self):\n",
    "        '''\n",
    "        - 1. Loading the correct climate cat csv\n",
    "        '''\n",
    "        # Test 1\n",
    "        climate_file = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        result = data_inputs.get_climate_cats(climate_file)\n",
    "        expected_result = pd.read_csv( BASE_PATH / 'py_ewr'/'climate_data/climate_cats.csv', index_col = 0)\n",
    "        assert_frame_equal(result, expected_result)\n",
    "        \n",
    "    \n",
    "    def test_get_EWR_table(self):\n",
    "        '''\n",
    "        - 1. Test for equal entries (no lost EWRs)\n",
    "        - 2. Test to ensure no bad EWRs make it through using a subset of EWRs\n",
    "        '''\n",
    "        # Test 1\n",
    "        proxies={} # Populate with your proxy settings\n",
    "        my_url = 'https://az3mdbastg001.blob.core.windows.net/mdba-public-data/NSWEWR_LIVE.csv'\n",
    "        s = requests.get(my_url, proxies=proxies).text\n",
    "        df = pd.read_csv(io.StringIO(s),\n",
    "                         usecols=['PlanningUnitID', 'PlanningUnitName',  'CompliancePoint/Node', 'gauge', 'code', 'start month',\n",
    "                                  'end month', 'frequency', 'events per year', 'duration', 'min event', 'flow threshold min', 'flow threshold max',\n",
    "                                  'max inter-event', 'within event gap tolerance', 'weirpool gauge', 'flow level volume', 'level threshold min',\n",
    "                                  'level threshold max', 'volume threshold', 'drawdown rate'],\n",
    "                         dtype='str'\n",
    "                        )\n",
    "        \n",
    "        # Get the cleaned dataset:\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        \n",
    "        total_len = len(EWR_table)+len(bad_EWRs)\n",
    "        self.assertEqual(len(df), total_len)\n",
    "        #-----------------------------------\n",
    "        # Test 2\n",
    "        # Send the dummy data through the function\n",
    "        dummy_EWR_table = 'https://az3mdbastg001.blob.core.windows.net/mdba-public-data/test_EWR_table_input.csv'\n",
    "        good, bad = data_inputs.get_EWR_table(dummy_EWR_table)\n",
    "        \n",
    "        # Load in expected output\n",
    "        expected_good = pd.read_csv('unit_testing_files/test_EWR_table_good_output.csv', dtype = 'str', encoding='cp1252')\n",
    "        expected_good = expected_good.fillna('')\n",
    "        expected_good['flow threshold max'].replace({'':'1000000'}, inplace = True)\n",
    "        expected_good['level threshold max'].replace({'':'1000000'}, inplace = True)\n",
    "        expected_bad = pd.read_csv('unit_testing_files/test_EWR_table_bad_output.csv', dtype = 'str', encoding='cp1252')\n",
    "        expected_bad = expected_bad.fillna('')\n",
    "        \n",
    "        assert_frame_equal(expected_good.reset_index(drop=True), good.reset_index(drop=True))\n",
    "        assert_frame_equal(expected_bad.reset_index(drop=True), bad.reset_index(drop=True))\n",
    "        \n",
    "        \n",
    "    def test_map_gauge_to_catchment(self):\n",
    "        '''\n",
    "        1. Run test data (stored on MDBA public data repository) through to see if gauges are mapping correctly\n",
    "        '''\n",
    "        \n",
    "        dummy_EWR_table = 'https://az3mdbastg001.blob.core.windows.net/mdba-public-data/test_EWR_table_input.csv'\n",
    "        \n",
    "        result = data_inputs.map_gauge_to_catchment(dummy_EWR_table)\n",
    "        expected_result = {'Namoi': {}, \n",
    "                           'Gwydir': {'418013': 'Gwydir at Gravesend '}, \n",
    "                           'Macquarie-Castlereagh': {'421004': 'Warren Weir ', '421090': 'Flows are to be met at both the gauge on the Macquarie River downstream Marebone and at Oxley Station ', \n",
    "                                                     '421022': 'Flows are to be met at both the gauge on the Macquarie River downstream Marebone and at Oxley Station '}, \n",
    "                           'Lachlan': {}, \n",
    "                           'Lower Darling': {'425020': 'Lake Wetherell & Tandure '}, \n",
    "                           'Barwon-Darling': {}, \n",
    "                           'Murray': {}, \n",
    "                           'Murrumbidgee': {}, \n",
    "                           'Border Rivers': {}, \n",
    "                           'Moonie': {}, \n",
    "                           'Condamine-Balonne': {}, \n",
    "                           'Warrego': {}, \n",
    "                           'Paroo': {},\n",
    "                          }\n",
    "        \n",
    "        self.assertDictEqual(result, expected_result)      \n",
    "        \n",
    "Test = test_data_inputs()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_data_inputs('test_convert_max_interevent'))\n",
    "suite.addTest(test_data_inputs('test_gauge_to_catchment'))\n",
    "suite.addTest(test_data_inputs('test_wy_to_climate'))\n",
    "suite.addTest(test_data_inputs('test_get_multi_gauges'))\n",
    "suite.addTest(test_data_inputs('test_get_simultaneous_gauges'))\n",
    "suite.addTest(test_data_inputs('test_get_climate_cats'))\n",
    "suite.addTest(test_data_inputs('test_get_EWR_table'))\n",
    "suite.addTest(test_data_inputs('test_get_EWR_table'))\n",
    "suite.addTest(test_data_inputs('test_map_gauge_to_catchment'))\n",
    "\n",
    "\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681feb08",
   "metadata": {},
   "source": [
    "### Testing the observed_handling.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2756c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....INFO:mdba_gauge_getter.gauge_get:NSW - Request 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://realtimedata.waternsw.com.au/cgi/webservice.pl?{\"params\":{\"site_list\":\"419039\",\"start_time\":\"20200701000000\",\"varfrom\":\"100.00\",\"interval\":\"day\",\"varto\":\"141.00\",\"datasource\":\"CP\",\"end_time\":\"20210630000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"},\"function\":\"get_ts_traces\",\"version\":\"2\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12590/2967290611.py:109: SettingWithCopyWarning:                                                                                                                                      \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  expected_detailed_results[col].iloc[i] = new_list\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 6.522s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_observed_handling(unittest.TestCase):\n",
    "    def test_observed_cleaner(self):\n",
    "        '''\n",
    "        1. Run sample data through and compare the expected output sample data\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Load sample input data and pass to function\n",
    "        input_df = pd.read_csv( 'unit_testing_files/observed_flows_test_input.csv')\n",
    "        dates = {'start_date': date(2014, 1, 1), 'end_date': date(2020, 1, 1)}\n",
    "        result = observed_handling.observed_cleaner(input_df, dates)\n",
    "        # Load sample output data and test\n",
    "        output_df = 'unit_testing_files/observed_flows_test_output.csv'\n",
    "        expected_result = pd.read_csv(output_df, index_col = 'Date')\n",
    "        expected_result.index = pd.to_datetime(expected_result.index, format='%Y-%m-%d')\n",
    "        expected_result.columns = ['419039']\n",
    "        assert_frame_equal(result, expected_result)\n",
    "    \n",
    "    def test_one_gauge_per_column(self):\n",
    "        '''\n",
    "        1. Run sample data through and compare to the expected output sample data\n",
    "        '''\n",
    "        # Test 1\n",
    "        # load and format expected output data\n",
    "        output_df = 'unit_testing_files/observed_flows_test_output.csv'\n",
    "        expected_result = pd.read_csv(output_df, index_col = 'Date')\n",
    "        expected_result.index = pd.to_datetime(expected_result.index, format='%Y-%m-%d')\n",
    "        expected_result.columns = ['419039']\n",
    "        # Load input data and pass to function\n",
    "        input_dataframe = pd.read_csv('unit_testing_files/observed_flows_test_input.csv')\n",
    "        gauge_iter = 419039\n",
    "        input_dataframe['Date'] = expected_result.index\n",
    "        result = observed_handling.one_gauge_per_column(input_dataframe, gauge_iter)\n",
    "        # assert equal test\n",
    "        assert_frame_equal(result, expected_result)\n",
    "        \n",
    "        \n",
    "    def test_remove_data_with_bad_QC(self):\n",
    "        '''\n",
    "        1. Run sample data through and compare to the expected output sample data to ensure bad data is removed\n",
    "        '''        \n",
    "        # Test 1\n",
    "        # Load sample input data:\n",
    "        input_dataframe = pd.read_csv('unit_testing_files/observed_flows_test_input_QC.csv', index_col = 'Date')\n",
    "        gauge_iter = 419039\n",
    "        qc_codes = data_inputs.get_bad_QA_codes()\n",
    "        # Load output sample data\n",
    "        expected_df = pd.read_csv('unit_testing_files/observed_flows_test_output_QC.csv', index_col = 'Date')\n",
    "\n",
    "        # Throw to the function\n",
    "        df = observed_handling.remove_data_with_bad_QC(input_dataframe, qc_codes)\n",
    "        \n",
    "        # Test for equality\n",
    "        assert_frame_equal(df, expected_df)\n",
    "    \n",
    "    \n",
    "    def test_categorise_gauges(self):\n",
    "        '''\n",
    "        1. gauges in all categories\n",
    "        2. gauges outside cats\n",
    "        '''\n",
    "        \n",
    "        level = ['425020', '425022', '425023', '414209', '4260501', '4260508','4260506']\n",
    "        flow = ['414203', '425010', '4260507', '4260505',  '421090', '421088', '421088', '421090', '421090', '421088', '421088', '421090', '421090', '421088', '421088', '421090', '421090', '421088', '421088', '421090', '409023', '409003']\n",
    "        all_gauges = level + flow\n",
    "        \n",
    "        f, l = observed_handling.categorise_gauges(all_gauges)\n",
    "\n",
    "        expected_level = copy.deepcopy(level)\n",
    "        expected_flow = copy.deepcopy(flow)\n",
    "        expected_flow = expected_flow + ['421022'] # Add in this one as it will be getting picked up for being associated with a simultaneious gauge\n",
    "        self.assertEqual(set(f), set(expected_flow))\n",
    "        self.assertEqual(set(l), set(expected_level))\n",
    "        \n",
    "        \n",
    "    def test_observed_handler(self):\n",
    "        '''\n",
    "        1. Test each part of the function are working correctly and producing an overall expected output\n",
    "        '''\n",
    "        \n",
    "        # Set up input parameters and pass to test function\n",
    "        gauges = ['419039']\n",
    "        dates = {'start_date': date(2020, 7, 1), 'end_date': date(2021, 6, 30)}\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "\n",
    "        detailed, summary = observed_handling.observed_handler(gauges, dates, allowance, climate)\n",
    "        \n",
    "        # Load and format expected results\n",
    "        expected_detailed_results = pd.read_csv('unit_testing_files/detailed_results_observed.csv', index_col = 0)\n",
    "        expected_detailed_results.index = expected_detailed_results.index.astype('object')\n",
    "        cols = expected_detailed_results.columns[expected_detailed_results.columns.str.contains('eventLength')]\n",
    "        expected_detailed_results[cols] = expected_detailed_results[cols].astype('float64')\n",
    "        for col in expected_detailed_results:\n",
    "            if 'daysBetweenEvents' in col:\n",
    "                for i, val in enumerate(expected_detailed_results[col]):\n",
    "                    new = expected_detailed_results[col].iloc[i]\n",
    "                    if new == '[]':\n",
    "                        new_list = []\n",
    "                    else:\n",
    "                        new = re.sub('\\[', '', new)\n",
    "                        new = re.sub('\\]', '', new)\n",
    "                        new = new.split(',')\n",
    "                        new_list = []\n",
    "                        for days in new:\n",
    "                            new_days = days.strip()\n",
    "                            new_days = int(new_days)\n",
    "                            new_list.append(new_days)\n",
    "\n",
    "                    expected_detailed_results[col].iloc[i] = new_list\n",
    "        \n",
    "        assert_frame_equal(detailed['observed']['419039']['Boggabri to Wee Waa'], expected_detailed_results)\n",
    "\n",
    "\n",
    "        \n",
    "Test = test_observed_handling()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_observed_handling('test_observed_cleaner'))\n",
    "suite.addTest(test_observed_handling('test_one_gauge_per_column'))\n",
    "suite.addTest(test_observed_handling('test_remove_data_with_bad_QC'))\n",
    "suite.addTest(test_observed_handling('test_categorise_gauges'))\n",
    "suite.addTest(test_observed_handling('test_observed_handler'))\n",
    "\n",
    "\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425ca03",
   "metadata": {},
   "source": [
    "### Testing the scenario_handling.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "962c4d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E.."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted and failed to read in dates in format: dd/mm/yyyy, attempting to look for dates in format: yyyy-mm-dd\n",
      "successfully read in data with yyyy-mm-dd formatting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted and failed to read in dates in format: dd/mm/yyyy, attempting to look for dates in format: yyyy-mm-dd\n",
      "successfully read in data with yyyy-mm-dd formatting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating scenarios:   0%|          | 0/1 [00:00<?, ?it/s]                                                                                                                                          \n",
      "E\n",
      "======================================================================\n",
      "ERROR: test_match_MDBA_nodes (__main__.test_scenario_handling)\n",
      "1. Ensure dataframe with flows and levels is split into two dataframes (one flow and one level dataframe)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/383273231.py\", line 7, in test_match_MDBA_nodes\n",
      "    model_metadata = data_inputs.get_MDBA_codes()\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/data_inputs.py\", line 159, in get_MDBA_codes\n",
      "    metadata = pd.read_csv( BASE_PATH / 'model_metadata/SiteID_MDBA.csv', engine = 'python', dtype=str)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1235, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 115, in __init__\n",
      "    ) = self._infer_columns()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 364, in _infer_columns\n",
      "    line = self._buffered_line()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 596, in _buffered_line\n",
      "    return self._next_line()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 696, in _next_line\n",
      "    orig_line = self._next_iter_line(row_num=self.pos + 1)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 760, in _next_iter_line\n",
      "    line = next(self.data)\n",
      "  File \"/home/pedro/.pyenv/versions/3.8.13/lib/python3.8/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 2023: invalid start byte\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_scenario_handler (__main__.test_scenario_handling)\n",
      "things to test here:\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/383273231.py\", line 245, in test_scenario_handler\n",
      "    detailed, summary = scenario_handling.scenario_handler(scenarios, model_format, allowance, climate)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/scenario_handling.py\", line 31, in scenario_handler\n",
      "    df_F, df_L = match_MDBA_nodes(df_clean, data_inputs.get_MDBA_codes())\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/data_inputs.py\", line 159, in get_MDBA_codes\n",
      "    metadata = pd.read_csv( BASE_PATH / 'model_metadata/SiteID_MDBA.csv', engine = 'python', dtype=str)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1235, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 115, in __init__\n",
      "    ) = self._infer_columns()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 364, in _infer_columns\n",
      "    line = self._buffered_line()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 596, in _buffered_line\n",
      "    return self._next_line()\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 696, in _next_line\n",
      "    orig_line = self._next_iter_line(row_num=self.pos + 1)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/io/parsers/python_parser.py\", line 760, in _next_iter_line\n",
      "    line = next(self.data)\n",
      "  File \"/home/pedro/.pyenv/versions/3.8.13/lib/python3.8/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 2023: invalid start byte\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 154.449s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=11 errors=2 failures=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_scenario_handling(unittest.TestCase):\n",
    "    def test_match_MDBA_nodes(self):\n",
    "        '''\n",
    "        1. Ensure dataframe with flows and levels is split into two dataframes (one flow and one level dataframe)\n",
    "        '''\n",
    "        # Set up input data and pass to test function:\n",
    "        model_metadata = data_inputs.get_MDBA_codes()\n",
    "        data_df = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                   'EUSTDS-1-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                   'EUSTUS-35-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                  }\n",
    "        df = pd.DataFrame(data = data_df)\n",
    "        df = df.set_index('Date')\n",
    "        \n",
    "        df_F, df_L = scenario_handling.match_MDBA_nodes(df, model_metadata)\n",
    "        \n",
    "        # Set up expected outputs and test:\n",
    "        data_expected_df_L = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                              '414209': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                             }\n",
    "        expected_df_L = pd.DataFrame(data_expected_df_L)\n",
    "        expected_df_L = expected_df_L.set_index('Date') \n",
    "        data_expected_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                              '414203': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                             }\n",
    "        expected_df_F = pd.DataFrame(data_expected_df_F)\n",
    "        expected_df_F = expected_df_F.set_index('Date')\n",
    "        \n",
    "        assert_frame_equal(df_F, expected_df_F)\n",
    "        assert_frame_equal(df_L, expected_df_L)\n",
    "    \n",
    "    def test_match_NSW_nodes(self):\n",
    "        '''\n",
    "        1. Check NSW model nodes are mapped correctly to their gauges\n",
    "        '''\n",
    "        # Set up input data and pass to test function:\n",
    "        model_metadata = data_inputs.get_NSW_codes()\n",
    "        data_df = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                   'Gauge: YCB_410134_BillabongCreek@Darlot: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                   'Gauge: YCB_410016 Billabong Creek @ Jerilderie: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                  }\n",
    "        df = pd.DataFrame(data = data_df)\n",
    "        df = df.set_index('Date')\n",
    "        \n",
    "        df_F, df_L = scenario_handling.match_NSW_nodes(df, model_metadata)\n",
    "        \n",
    "        # Set up expected outputs and test:\n",
    "        data_expected_df_L = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))}\n",
    "        expected_df_L = pd.DataFrame(data_expected_df_L)\n",
    "        expected_df_L = expected_df_L.set_index('Date')\n",
    "        \n",
    "        data_expected_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                              '410134': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                              '410016': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                             }\n",
    "        expected_df_F = pd.DataFrame(data_expected_df_F)\n",
    "        expected_df_F = expected_df_F.set_index('Date')\n",
    "        \n",
    "        assert_frame_equal(df_F, expected_df_F)\n",
    "        assert_frame_equal(df_L, expected_df_L)\n",
    "    \n",
    "    def test_extract_gauge_from_string(self):\n",
    "        '''\n",
    "        1. Check gauge string is pulled from various strings likely encountered during standard program run\n",
    "        '''\n",
    "        # Test 1\n",
    "        input_string = '409025'\n",
    "        return_gauge = scenario_handling.extract_gauge_from_string(input_string)\n",
    "        expected_gauge = '409025'\n",
    "        self.assertEqual(return_gauge, expected_gauge)\n",
    "        # Test 2\n",
    "        input_string = ' 409025 '\n",
    "        return_gauge = scenario_handling.extract_gauge_from_string(input_string)\n",
    "        expected_gauge = '409025'\n",
    "        self.assertEqual(return_gauge, expected_gauge)\n",
    "        # Test 3\n",
    "        input_string = '409025---999'\n",
    "        return_gauge = scenario_handling.extract_gauge_from_string(input_string)\n",
    "        expected_gauge = '409025'\n",
    "        self.assertEqual(return_gauge, expected_gauge)\n",
    "\n",
    "        \n",
    "    def test_cleaner_IQQM_10000yr(self):\n",
    "        '''\n",
    "        1. Check date formatting and correct allocationo of gauge data to either flow/level dataframes\n",
    "        '''\n",
    "        # Set up input data and pass to test function:\n",
    "        date_start = '0105-07-01'\n",
    "        date_end = '9999-06-30'\n",
    "        date_range = pd.period_range(date_start, date_end, freq = 'D')\n",
    "        data_for_input_df = {'Date': date_range, '409025': [50]*3613709}\n",
    "        input_df = pd.DataFrame(data_for_input_df)\n",
    "        str_df = input_df.copy(deep=True)\n",
    "        str_df['Date'] = str_df['Date'].astype('str')\n",
    "        def add_0 (row):\n",
    "            j = row.split('-')\n",
    "            if len(j[0]) < 4:\n",
    "                new_row = '0'+ row\n",
    "            else:\n",
    "                new_row = row\n",
    "            return new_row\n",
    "        str_df['Date'] = str_df['Date'].apply(add_0)\n",
    "        str_df = str_df.set_index('Date')\n",
    "        df_f, df_l = scenario_handling.cleaner_IQQM_10000yr(str_df)\n",
    "        \n",
    "        # Set up expected data and test:\n",
    "        expected_df_flow = input_df.copy(deep=True)\n",
    "        expected_df_flow = expected_df_flow.set_index('Date')\n",
    "        expected_df_flow.columns = ['409025']\n",
    "        expected_df_level = pd.DataFrame(index = expected_df_flow.index)\n",
    "        \n",
    "        assert_frame_equal(expected_df_level, df_l)\n",
    "        assert_frame_equal(expected_df_flow, df_f)\n",
    "        \n",
    "        \n",
    "    def test_cleaner_NSW(self):\n",
    "        '''\n",
    "        1. Test date formatting is applied correctly\n",
    "        '''\n",
    "        # Set up input data and pass to test function:\n",
    "        model_metadata = data_inputs.get_NSW_codes()\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        date_strings = dates.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n",
    "        data_df = {'Date': date_strings,\n",
    "                   'Gauge: YCB_410134_BillabongCreek@Darlot: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                   'Gauge: YCB_410016 Billabong Creek @ Jerilderie: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                  }\n",
    "        df = pd.DataFrame(data = data_df)\n",
    "        df_clean = scenario_handling.cleaner_NSW(df)\n",
    "        # Set up expected output data and test:\n",
    "        data_expected_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                              'Gauge: YCB_410134_BillabongCreek@Darlot: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                              'Gauge: YCB_410016 Billabong Creek @ Jerilderie: Downstream Flow': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                             }\n",
    "        expected_df_F = pd.DataFrame(data_expected_df_F)\n",
    "        expected_df_F = expected_df_F.set_index('Date')\n",
    "        assert_frame_equal(df_clean, expected_df_F)\n",
    "        \n",
    "        \n",
    "    def test_cleaner_MDBA(self):\n",
    "        '''\n",
    "        1. Test date formatting is applied correctly\n",
    "        '''\n",
    "        # Set up input data and pass to test function:\n",
    "        data_df = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                   'EUSTDS-1-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                   'EUSTUS-35-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                  }\n",
    "        df = pd.DataFrame(data = data_df)\n",
    "        df['Dy'], df['Mn'], df['Year'] = df['Date'].dt.day, df['Date'].dt.month, df['Date'].dt.year\n",
    "        df = df.drop(['Date'], axis = 1)\n",
    "        \n",
    "        df_clean = scenario_handling.cleaner_MDBA(df)\n",
    "        # Set up expected output data and test:\n",
    "        data_expected_df = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                              'EUSTDS-1-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10,\n",
    "                              'EUSTUS-35-8': [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10\n",
    "                             }\n",
    "        expected_df = pd.DataFrame(data_expected_df)\n",
    "        expected_df = expected_df.set_index('Date')\n",
    "        \n",
    "        assert_frame_equal(df_clean, expected_df)\n",
    "        \n",
    "        \n",
    "    def test_build_NSW_columns(self):\n",
    "        '''\n",
    "        1. Check data columns are renamed based on header data\n",
    "        '''\n",
    "        # Load in test input data and pass to test function:\n",
    "        input_file = 'unit_testing_files/NSW_source_res_test_file.csv'\n",
    "        data, header = scenario_handling.unpack_model_file(input_file, 'Date', 'Field')\n",
    "        data = scenario_handling.build_NSW_columns(data, header)\n",
    "        # Load in test expected output data and test:\n",
    "        expected_result = pd.read_csv('unit_testing_files/NSW_source_res_test_file_flow_result.csv')\n",
    "        assert_frame_equal(data, expected_result)\n",
    "        \n",
    "        \n",
    "    def test_build_MDBA_columns(self):\n",
    "        '''\n",
    "        1. Ensure data column names are correctly taken from the header data\n",
    "        '''\n",
    "        # Load input data and send to test function:\n",
    "        input_file = 'unit_testing_files/MDBA_bigmod_test_file.csv'\n",
    "        data, header = scenario_handling.unpack_model_file(input_file, 'Dy', 'Field')\n",
    "        data = scenario_handling.build_MDBA_columns(data, header)\n",
    "        data = data.astype({'Dy': 'float64'})\n",
    "        # Load expected output data, format, and test:\n",
    "        expected_result = pd.read_csv('unit_testing_files/MDBA_bigmod_test_file_flow_result.csv')\n",
    "        expected_result = expected_result.astype({'Dy': 'float64'})\n",
    "        assert_frame_equal(data, expected_result)        \n",
    "    \n",
    "    \n",
    "    def test_unpack_model_file(self):\n",
    "        '''\n",
    "        1. Test MDBA style file ingestion\n",
    "        2. Test NSW style file ingestion\n",
    "        '''\n",
    "        \n",
    "        # Test 1\n",
    "        # Load test data and expected output data\n",
    "        file_to_pass = 'unit_testing_files/MDBA_bigmod_test_file.csv'\n",
    "        expected_header = pd.read_csv('unit_testing_files/MDBA_bigmod_test_file_header_result.csv', dtype={'Site':'str', 'Measurand': 'str', 'Quality': 'str'})\n",
    "        expected_flow = pd.read_csv('unit_testing_files/MDBA_bigmod_test_file_flow_result.csv', dtype={'Dy':'int', 'Mn': 'int', 'Year': 'int'})\n",
    "        # Pass to test function and test\n",
    "        flow, header = scenario_handling.unpack_model_file(file_to_pass, 'Dy', 'Field')\n",
    "        assert_frame_equal(flow, expected_flow)\n",
    "        assert_frame_equal(header, expected_header)\n",
    "        #------------------------------------------\n",
    "        # Test 2\n",
    "        # Load test data and expected output data:\n",
    "        file_to_pass = 'unit_testing_files/NSW_source_res_test_file.csv'\n",
    "        expected_header = pd.read_csv('unit_testing_files/NSW_source_res_test_file_header_result.csv')\n",
    "        expected_flow = pd.read_csv('unit_testing_files/NSW_source_res_test_file_flow_result.csv')\n",
    "        expected_flow.columns = ['Date', '1>Data Sources>Data Sources@Climate Data@FAO56_res_csv@049050_SILO_FAO56.csv', '2>Data Sources>Data Sources@Climate Data@Mwet_res_csv@049050_SILO_Mwet.csv']\n",
    "        # Pass to test function and test\n",
    "        flow, header = scenario_handling.unpack_model_file(file_to_pass, 'Date', 'Field')  \n",
    "        assert_frame_equal(flow, expected_flow)\n",
    "        assert_frame_equal(header, expected_header)\n",
    "\n",
    "        \n",
    "    def test_unpack_IQQM_10000yr(self):\n",
    "        '''\n",
    "        1. Check gauge strings are pulled from column names and saved in place of the original string \n",
    "        '''\n",
    "        file_to_pass ='unit_testing_files/NSW_10000yr_test_file.csv'\n",
    "        flow = scenario_handling.unpack_IQQM_10000yr(file_to_pass)\n",
    "        \n",
    "        expected_flow = pd.read_csv('unit_testing_files/NSW_10000yr_test_file.csv', index_col = 'Date')\n",
    "        expected_flow.columns = ['418013']\n",
    "        \n",
    "        assert_frame_equal(flow, expected_flow)\n",
    "    \n",
    "    \n",
    "    def test_scenario_handler(self):\n",
    "        '''things to test here:\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Testing the MDBA bigmod format:\n",
    "        # Input params\n",
    "        scenarios = {'Low_flow_EWRs_Bidgee_410007': 'unit_testing_files/Low_flow_EWRs_Bidgee_410007.csv'}\n",
    "        model_format = 'Bigmod - MDBA'\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass to the function\n",
    "        detailed, summary = scenario_handling.scenario_handler(scenarios, model_format, allowance, climate)\n",
    "        # Expected output params\n",
    "        expected_detailed_results = pd.read_csv('unit_testing_files/detailed_results_test.csv', index_col=0)\n",
    "        expected_detailed_results.index = expected_detailed_results.index.astype('object')\n",
    "        cols = expected_detailed_results.columns[expected_detailed_results.columns.str.contains('eventLength')]\n",
    "        expected_detailed_results[cols] = expected_detailed_results[cols].astype('float64')\n",
    "        for col in expected_detailed_results:\n",
    "            if 'daysBetweenEvents' in col:\n",
    "                for i, val in enumerate(expected_detailed_results[col]):\n",
    "                    new = expected_detailed_results[col].iloc[i]\n",
    "                    if new == '[]':\n",
    "                        new_list = []\n",
    "                    else:\n",
    "                        new = re.sub('\\[', '', new)\n",
    "                        new = re.sub('\\]', '', new)\n",
    "                        new = new.split(',')\n",
    "                        new_list = []\n",
    "                        for days in new:\n",
    "                            new_days = days.strip()\n",
    "                            new_days = int(new_days)\n",
    "                            new_list.append(new_days)\n",
    "\n",
    "                    expected_detailed_results[col].iloc[i] = new_list\n",
    "        # Test\n",
    "        assert_frame_equal(detailed['Low_flow_EWRs_Bidgee_410007']['410007']['Upper Yanco Creek'], expected_detailed_results)\n",
    "        \n",
    "Test = test_scenario_handling()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_scenario_handling('test_match_MDBA_nodes'))\n",
    "suite.addTest(test_scenario_handling('test_match_NSW_nodes'))\n",
    "suite.addTest(test_scenario_handling('test_extract_gauge_from_string'))\n",
    "suite.addTest(test_scenario_handling('test_cleaner_IQQM_10000yr'))\n",
    "suite.addTest(test_scenario_handling('test_cleaner_NSW'))\n",
    "suite.addTest(test_scenario_handling('test_cleaner_MDBA'))\n",
    "suite.addTest(test_scenario_handling('test_build_NSW_columns'))\n",
    "suite.addTest(test_scenario_handling('test_build_MDBA_columns'))\n",
    "suite.addTest(test_scenario_handling('test_unpack_model_file'))\n",
    "suite.addTest(test_scenario_handling('test_unpack_IQQM_10000yr'))\n",
    "suite.addTest(test_scenario_handling('test_scenario_handler'))\n",
    "\n",
    "\n",
    "unittest.TextTestRunner().run(suite)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c0704",
   "metadata": {},
   "source": [
    "### Testing the evaluate_EWRs.py module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba944aca",
   "metadata": {},
   "source": [
    "#### Handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a630a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....E...FEEEE.\n",
      "======================================================================\n",
      "ERROR: test_weirpool_handle (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 220, in test_weirpool_handle\n",
      "    PU_df, events = evaluate_EWRs.weirpool_handle(PU, gauge, EWR, EWR_table, df_F, df_L, PU_df, allowance)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 313, in weirpool_handle\n",
      "    EWR_info = get_EWRs(PU, gauge, EWR, EWR_table, allowance, pull)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 36, in get_EWRs\n",
      "    start_date = str(component_pull(EWR_table, gauge, PU, EWR, 'start month'))\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 17, in component_pull\n",
      "    component = list(EWR_table[((EWR_table['gauge'] == gauge) &\n",
      "IndexError: list index out of range\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_cumulative_handle_multi (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 442, in test_cumulative_handle_multi\n",
      "    PU_df, events = evaluate_EWRs.cumulative_handle_multi(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 446, in cumulative_handle_multi\n",
      "    EWR_info = get_EWRs(PU, gauge, EWR, EWR_table, allowance, pull)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 36, in get_EWRs\n",
      "    start_date = str(component_pull(EWR_table, gauge, PU, EWR, 'start month'))\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 17, in component_pull\n",
      "    component = list(EWR_table[((EWR_table['gauge'] == gauge) &\n",
      "IndexError: list index out of range\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_flow_handle_sim (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 483, in test_flow_handle_sim\n",
      "    PU_df, events = evaluate_EWRs.flow_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 472, in flow_handle_sim\n",
      "    EWR_info1 = get_EWRs(PU, gauge, EWR, EWR_table, allowance, pull)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 36, in get_EWRs\n",
      "    start_date = str(component_pull(EWR_table, gauge, PU, EWR, 'start month'))\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 17, in component_pull\n",
      "    component = list(EWR_table[((EWR_table['gauge'] == gauge) &\n",
      "IndexError: list index out of range\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_lowflow_handle_sim (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 524, in test_lowflow_handle_sim\n",
      "    PU_df, events = evaluate_EWRs.lowflow_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 499, in lowflow_handle_sim\n",
      "    EWR_info1 = get_EWRs(PU, gauge, EWR, EWR_table, allowance, pull)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 36, in get_EWRs\n",
      "    start_date = str(component_pull(EWR_table, gauge, PU, EWR, 'start month'))\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 17, in component_pull\n",
      "    component = list(EWR_table[((EWR_table['gauge'] == gauge) &\n",
      "IndexError: list index out of range\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_ctf_handle_sim (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 565, in test_ctf_handle_sim\n",
      "    PU_df, events = evaluate_EWRs.ctf_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 525, in ctf_handle_sim\n",
      "    EWR_info1 = get_EWRs(PU, gauge, EWR, EWR_table, allowance, pull)\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 36, in get_EWRs\n",
      "    start_date = str(component_pull(EWR_table, gauge, PU, EWR, 'start month'))\n",
      "  File \"/home/pedro/code/ewr_fork/EWR_tool/py_ewr/evaluate_EWRs.py\", line 17, in component_pull\n",
      "    component = list(EWR_table[((EWR_table['gauge'] == gauge) &\n",
      "IndexError: list index out of range\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_ctf_handle_multi (__main__.test_evaluate_EWRs_handling)\n",
      "1. Ensure all parts of the function generate expected output\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12590/129174869.py\", line 411, in test_ctf_handle_multi\n",
      "    assert_frame_equal(PU_df, expected_PU_df)\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/_testing/asserters.py\", line 1333, in assert_frame_equal\n",
      "    assert_series_equal(\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/_testing/asserters.py\", line 1098, in assert_series_equal\n",
      "    _testing.assert_almost_equal(\n",
      "  File \"pandas/_libs/testing.pyx\", line 52, in pandas._libs.testing.assert_almost_equal\n",
      "  File \"pandas/_libs/testing.pyx\", line 167, in pandas._libs.testing.assert_almost_equal\n",
      "  File \"/home/pedro/code/ewr_fork/.venv/lib/python3.8/site-packages/pandas/_testing/asserters.py\", line 682, in raise_assert_detail\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: DataFrame.iloc[:, 0] (column name=\"CF_eventYears\") are different\n",
      "\n",
      "DataFrame.iloc[:, 0] (column name=\"CF_eventYears\") values are different (25.0 %)\n",
      "[index]: [2012, 2013, 2014, 2015]\n",
      "[left]:  [1, 0, 0, 1]\n",
      "[right]: [1, 0, 1, 1]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 15 tests in 7.681s\n",
      "\n",
      "FAILED (failures=1, errors=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=15 errors=5 failures=1>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_evaluate_EWRs_handling(unittest.TestCase):\n",
    "    def test_ctf_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # set up input data\n",
    "        PU = 'PU_0000283'\n",
    "        gauge = '410007'\n",
    "        EWR = 'CF1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*1+[0]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*10+[0]*345+[0]*1+[0]*9 + [0]*5+[0]*351+[0]*10}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function:\n",
    "        PU_df, events = evaluate_EWRs.ctf_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output - PU_df\n",
    "        data = {'CF1_eventYears': [0,0,0,1], 'CF1_numAchieved': [0,0,0,1], 'CF1_numEvents': [0,0,0,1], 'CF1_eventLength': [0.0,0.0,0.0,1461.0], 'CF1_totalEventDays': [0,0,0,1461], 'CF1_daysBetweenEvents': [[],[],[],[]], \n",
    "                'CF1_missingDays': [0,0,0,0], 'CF1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())        \n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events\n",
    "        expected_events = {2012:[], 2013:[], 2014:[], 2015:[[0]*1461]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i]) \n",
    "    \n",
    "        \n",
    "    def test_lowflow_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000283'\n",
    "        gauge = '410007'\n",
    "        EWR = 'BF1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*1+[250]*350+[0]*9+[0]*5 + [0]*360+[0]*5 + [0]*2+[250]*345+[0]*1+[250]*17 + [0]*5+[250]*351+[250]*10}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function\n",
    "        PU_df, events = evaluate_EWRs.lowflow_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output data - PU_df, and testing\n",
    "        data = {'BF1_eventYears': [0,0,1,1], 'BF1_numAchieved': [0,0,1,1], 'BF1_numEvents': [0,0,1,1], 'BF1_eventLength': [350.0,0.0,181.0,361.0], 'BF1_totalEventDays': [350,0,362,361], \n",
    "                'BF1_daysBetweenEvents': [[],[],[381],[]],\n",
    "                'BF1_missingDays': [0,0,0,0], 'BF1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "\n",
    "        # Setting up expected output - events, and testing\n",
    "        expected_events = {2012:[[250]*350], 2013:[], 2014:[[250]*345, [250]*17], 2015:[[250]*351+[250]*10]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])  \n",
    "    \n",
    "    def test_flow_handle(self):\n",
    "        '''Things to calc in this function:\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Setting up input data\n",
    "        PU = 'PU_0000283'\n",
    "        gauge = '410007'\n",
    "        EWR = 'SF1_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*1+[250]*350+[450]*10+[0]*4 + [0]*360+[450]*5 + [450]*5+[250]*345+[0]*1+[450]*14 + [0]*5+[450]*10+[0]*1+[450]*10+[250]*330+[450]*10}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function\n",
    "        PU_df, events = evaluate_EWRs.flow_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'SF1_S_eventYears': [0,0,1,1], 'SF1_S_numAchieved': [0,0,1,1], 'SF1_S_numEvents': [1,0,2,3], 'SF1_S_eventLength': [10.0,0.0,12.0,10.0], 'SF1_S_totalEventDays': [10,0,24,30], \n",
    "                'SF1_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'SF1_S_missingDays': [0,0,0,0], 'SF1_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[450]*10], 2013:[], 2014:[[450]*5+[450]*5, [450]*14], 2015:[[450]*10, [450]*10, [450]*10]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i]) \n",
    "    \n",
    "    def test_cumulative_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000040'\n",
    "        gauge = '418068'\n",
    "        EWR = 'OB3_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*1+[0]*350+[10000]*1+[3000]*4+[0]*9 + [0]*360+[450]*3+[19000]*1+[1000]*1 + [450]*5+[250]*345+[0]*1+[0]*13+[5000]*1 + [5000]*4+[450]*10+[0]*2+[450]*10+[250]*330+[450]*10}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function\n",
    "        PU_df, events = evaluate_EWRs.cumulative_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'OB3_S_eventYears': [1,0,0,1], 'OB3_S_numAchieved': [1,0,0,1], 'OB3_S_numEvents': [1,0,0,1], 'OB3_S_eventLength': [5.0,0.0,0.0,5.0], 'OB3_S_totalEventDays': [5,0,0,5], \n",
    "                'OB3_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'OB3_S_missingDays': [0,0,0,0], 'OB3_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing \n",
    "        expected_events = {2012:[[10000]*1+[3000]*4], 2013:[], 2014:[], 2015:[[5000]*1+[5000]*4]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "\n",
    "    def test_level_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000266'\n",
    "        gauge = '425022'\n",
    "        EWR = 'LLLF'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_L = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*1+[0]*260+[56]*90+[0]*1+[0]*4+[0]*9 + [56]*45+[55.9]*1+[56]*45+[0]*269+[0]*3+[19000]*1+[1000]*1 + [0]*5+[0]*345+[0]*1+[0]*13+[56]*1 + [56]*89+[0]*4+[0]*10+[0]*3+[0]*10+[0]*230+[0]*20}\n",
    "        df_L = pd.DataFrame(data = data_for_df_L)\n",
    "        df_L = df_L.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function\n",
    "        PU_df, events = evaluate_EWRs.level_handle(PU, gauge, EWR, EWR_table, df_L, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df and test\n",
    "        data = {'LLLF_eventYears': [1,0,0,0], 'LLLF_numAchieved': [1,0,0,0], 'LLLF_numEvents': [1,0,0,0], 'LLLF_eventLength': [90.0,0.0,0.0,0], 'LLLF_totalEventDays': [90,0,0,0], \n",
    "                'LLLF_daysBetweenEvents': [[],[],[],[1110]],\n",
    "                'LLLF_missingDays': [0,0,0,0], 'LLLF_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and test\n",
    "        expected_events = {2012:[[56]*90], 2013:[], 2014:[], 2015:[]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i]) \n",
    "    \n",
    "    def test_weirpool_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000260'\n",
    "        gauge = '414203'\n",
    "        wp_gauge = '414209'\n",
    "        EWR = 'WP1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        # input data for df_L:\n",
    "        levels = [47.3]*100 \n",
    "        reduction_max = 0.04\n",
    "        for i, level in enumerate(levels):\n",
    "            levels[i] = levels[i-1]-reduction_max # Levels declining at acceptable rate\n",
    "        exceeding_levels = [47.3]*100 \n",
    "        reduction_max = 0.05\n",
    "        for i, level in enumerate(exceeding_levels):\n",
    "            exceeding_levels[i] = exceeding_levels[i-1]-reduction_max # Levels exceeding the acceptable rate: \n",
    "        data_for_df_L = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         wp_gauge: [0]*187+[47.3]*90+[0]*88 + [47.3]*90+[0]*275 + [0]*187+levels+[0]*78 + [0]*187+exceeding_levels+[0]*79}\n",
    "        df_L = pd.DataFrame(data = data_for_df_L)\n",
    "        df_L = df_L.set_index('Date')\n",
    "        # input data for df_F:\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*187+[2500]*90+[0]*88 + [2500]*90+[0]*275 + [0]*187+[2500]*100+[0]*78 + [0]*187+[2500]*100+[0]*79}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Passing input data to test function\n",
    "        PU_df, events = evaluate_EWRs.weirpool_handle(PU, gauge, EWR, EWR_table, df_F, df_L, PU_df, allowance)\n",
    "        # Setting up expected output data - PU_df - and testing\n",
    "        data = {'WP1_eventYears': [1,0,1,0], 'WP1_numAchieved': [1,0,1,0], 'WP1_numEvents': [1,0,1,0], 'WP1_eventLength': [90.0,0.0,90.0,0.0], 'WP1_totalEventDays': [90,0,90,0], \n",
    "                'WP1_daysBetweenEvents': [[],[],[],[]],\n",
    "                'WP1_missingDays': [0,0,0,0], 'WP1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[2500]*90], 2013:[], 2014:[[2500]*90], 2015:[]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "    \n",
    "    def test_nest_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000253'\n",
    "        gauge = '409025'\n",
    "        EWR = 'NestS1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        # input data up df_L:\n",
    "        # flows declining at acceptable rate:\n",
    "        acceptable_flows = [10000]*10\n",
    "        reduction_max = 5.9\n",
    "        for i, flow in enumerate(acceptable_flows):\n",
    "            acceptable_flows[i] = acceptable_flows[i-1]-(reduction_max/100*acceptable_flows[i-1])\n",
    "        acceptable_flows = acceptable_flows + [5300]*50\n",
    "        # flows declining at unnacceptable rate:\n",
    "        unnacceptable_flows = [10000]*10\n",
    "        reduction_max = 7\n",
    "        for i, flow in enumerate(unnacceptable_flows):\n",
    "            unnacceptable_flows[i] = unnacceptable_flows[i-1]-(reduction_max/100*unnacceptable_flows[i-1])\n",
    "        unnacceptable_flows = unnacceptable_flows + [5300]*50\n",
    "        # flows declining at acceptable rate but going below the threshold\n",
    "        threshold_flows = [10000]*10\n",
    "        reduction_max = 6\n",
    "        for i, flow in enumerate(threshold_flows):\n",
    "            threshold_flows[i] = threshold_flows[i-1]-(reduction_max/100*threshold_flows[i-1])\n",
    "        threshold_flows = threshold_flows + [5300]*50\n",
    "        # input data for df_F:\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [0]*76+acceptable_flows+[0]*229 + [0]*76+unnacceptable_flows+[0]*229 + [0]*76+threshold_flows+[0]*229 + [0]*77+threshold_flows+[0]*229}\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function:\n",
    "        PU_df, events = evaluate_EWRs.nest_handle(PU, gauge, EWR, EWR_table, df_F, df_L, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'NestS1_eventYears': [1,0,0,0], 'NestS1_numAchieved': [1,0,0,0], 'NestS1_numEvents': [1,0,0,0], 'NestS1_eventLength': [60.0,0.0,0.0,0.0], 'NestS1_totalEventDays': [60,0,0,0],\n",
    "                'NestS1_daysBetweenEvents': [[],[],[],[1325]],\n",
    "                'NestS1_missingDays': [0,0,0,0], 'NestS1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[acceptable_flows], 2013:[], 2014:[], 2015:[]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "    \n",
    "    def test_flow_handle_multi(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000130'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421088'\n",
    "        EWR = 'LF1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [0]*76+[1250]*5+[0]*229+[0]*55 + [0]*76+[0]*55+[0]*231+[1250]*3 + [1250]*3+[0]*76+[0]*50+[1250]*5+[0]*231 + [0]*77+[1250]*5+[0]*229+[0]*55,\n",
    "                         gauge2: [0]*76+[1250]*5+[0]*229+[0]*55 + [0]*76+[0]*55+[0]*231+[1250]*3 + [1250]*3+[0]*76+[0]*50+[1250]*5+[0]*231 + [0]*76+[1250]*5+[0]*230+[0]*55\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Send input data to test function\n",
    "        PU_df, events = evaluate_EWRs.flow_handle_multi(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'LF1_eventYears': [1,0,1,0], 'LF1_numAchieved': [1,0,2,0], 'LF1_numEvents': [1,0,2,0], 'LF1_eventLength': [5.0,0.0,5.5,0.0], 'LF1_totalEventDays': [5,0,11,0],\n",
    "                'LF1_daysBetweenEvents': [[],[],[],[]],\n",
    "                'LF1_missingDays': [0,0,0,0], 'LF1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)    \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[2500]*5], 2013:[], 2014:[[2500]*6, [2500]*5], 2015:[]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])  \n",
    "    \n",
    "    def test_lowflow_handle_multi(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Input data\n",
    "        PU = 'PU_0000130'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421088'\n",
    "        EWR = 'BF1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [50]*76+[1250]*5+[50]*229+[50]*15+[0]*40 + [50]*3+[0]*76+[0]*50+[0]*5+[0]*231 + [50]*75+[0]*50+[50]*230+[50]*10 + [0]*77+[50]*5+[0]*229+[50]*55,\n",
    "                         gauge2: [50]*76+[1250]*5+[50]*229+[0]*40+[50]*15 + [50]*3+[0]*76+[0]*50+[0]*5+[0]*231 + [50]*75+[0]*50+[50]*230+[50]*10 + [0]*76+[50]*5+[0]*230+[50]*55\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.lowflow_handle_multi(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'BF1_eventYears': [0,0,1,0], 'BF1_numAchieved': [0,0,1,0], 'BF1_numEvents': [0,0,1,0], 'BF1_eventLength': [310.0,3.0,157.5,29.5], 'BF1_totalEventDays': [310,3,315,59],\n",
    "                'BF1_daysBetweenEvents': [[],[362],[],[77, 230]],\n",
    "                'BF1_missingDays': [0,0,0,0], 'BF1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)    \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[100]*76+[2500]*5+[100]*229], 2013:[[100]*3], 2014:[[100]*75, [100]*230+[100]*10], 2015:[[100]*4, [100]*55]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "    \n",
    "    def test_ctf_handle_multi(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up the input data\n",
    "        PU = 'PU_0000130'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421088'\n",
    "        EWR = 'CF'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [0]*1+[2]*350+[0]*9+[0]*5 + [2]*360+[0]*5 + [0]*10+[2]*345+[0]*1+[2]*9 + [0]*5+[0]*351+[0]*10,\n",
    "                         gauge2: [0]*1+[2]*350+[0]*9+[0]*5 + [2]*360+[0]*5 + [0]*10+[2]*345+[0]*1+[2]*9 + [0]*5+[0]*351+[0]*10\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to the test function\n",
    "        PU_df, events = evaluate_EWRs.ctf_handle_multi(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'CF_eventYears': [1,0,1,1], 'CF_numAchieved': [2,0,2,1], 'CF_numEvents': [2,0,2,1], 'CF_eventLength': [7.5,0.0,8.0,366.0], 'CF_totalEventDays': [15,0,16,366],\n",
    "                'CF_daysBetweenEvents': [[350],[360],[345,9],[]],\n",
    "                'CF_missingDays': [0,0,0,0], 'CF_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)    \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[0]*1, [0]*9+[0]*5], 2013:[], 2014:[[0]*15, [0]*1], 2015:[[0]*366]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "\n",
    "    def test_cumulative_handle_multi(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000132'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421088'\n",
    "        EWR = 'OB/WS1_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [0]*1+[0]*260+[334]*90+[0]*5+[0]*9 + [0]*310+[0]*3+[0]*1+[0]*1+[500]*50 + [500]*40+[0]*310+[0]*1+[0]*13+[0]*1 + [5000]*4+[500]*90+[500]*90+[450]*10+[0]*2+[450]*10+[250]*150+[450]*10,\n",
    "                         gauge2: [0]*1+[0]*260+[334]*90+[0]*5+[0]*9 + [0]*310+[0]*3+[0]*1+[0]*1+[500]*50 + [500]*40+[0]*310+[0]*1+[0]*13+[0]*1 + [5000]*4+[500]*90+[500]*90+[450]*10+[0]*2+[450]*10+[250]*150+[450]*10\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.cumulative_handle_multi(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'OB/WS1_S_eventYears': [1,1,1,1], 'OB/WS1_S_numAchieved': [1,1,1,2], 'OB/WS1_S_numEvents': [1,1,1,2], 'OB/WS1_S_eventLength': [90,90.0,90.0,90.0], 'OB/WS1_S_totalEventDays': [90,90,90,180],\n",
    "                'OB/WS1_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'OB/WS1_S_missingDays': [0,0,0,0], 'OB/WS1_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)   \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[334*2]*90], 2013:[[0]*30+[500*2]*60], 2014:[[0]*66+[5000*2]*4+[500*2]*20], 2015:[[500*2]*90, [500*2]*70+[450*2]*10+[0]*2+[450*2]*8]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])     \n",
    "    \n",
    "    def test_flow_handle_sim(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000131'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421022'\n",
    "        EWR = 'LF1_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [0]*76+[1000]*5+[0]*229+[0]*55 + [0]*76+[0]*55+[0]*231+[1000]*3 + [1000]*3+[0]*76+[0]*50+[1000]*5+[0]*231 + [0]*77+[1000]*5+[0]*229+[0]*55,\n",
    "                         gauge2: [0]*76+[1000]*5+[0]*229+[0]*55 + [0]*76+[0]*55+[0]*231+[1000]*3 + [1000]*3+[0]*76+[0]*50+[1000]*5+[0]*231 + [0]*76+[1000]*5+[0]*230+[0]*55\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.flow_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'LF1_S_eventYears': [1,0,1,0], 'LF1_S_numAchieved': [1,0,2,0], 'LF1_S_numEvents': [1,0,2,0], 'LF1_S_eventLength': [5.0,0.0,5.5,0.0], 'LF1_S_totalEventDays': [5,0,11,0],\n",
    "                'LF1_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'LF1_S_missingDays': [0,0,0,0], 'LF1_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "#         print(PU_df.head())\n",
    "#         print(expected_PU_df.head())\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[1000]*5], 2013:[], 2014:[[1000]*6, [1000]*5], 2015:[]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])  \n",
    "    \n",
    "    def test_lowflow_handle_sim(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000131'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421022'\n",
    "        EWR = 'BF1'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [0]*76+[65]*280+[0]*9 + [0]*76+[0]*9+[65]*280 + [0]*80+[0]*9+[65]*276 + [65]*270+[0]*76+[0]*14+[65]*6,\n",
    "                         gauge2: [0]*76+[65]*280+[0]*9 + [65]*280+[0]*76+[0]*9 + [0]*80+[0]*9+[65]*276 + [65]*270+[0]*76+[0]*14+[65]*6\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.lowflow_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output - PU_df - and test\n",
    "        # Note the floats that get returned in the total event days series. This is because the totals of the two series are averaged.\n",
    "        data = {'BF1_eventYears': [1,1,1,0], 'BF1_numAchieved': [1,1,1,0], 'BF1_numEvents': [1,1,1,0], 'BF1_eventLength': [280.0,280.0,276.0,138.0], 'BF1_totalEventDays': [280.0,280.0,276.0,276.0],\n",
    "                'BF1_daysBetweenEvents': [[76],[94],[89],[90]],\n",
    "                'BF1_missingDays': [0,0,0,0], 'BF1_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "        assert_frame_equal(PU_df, expected_PU_df)\n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events1 = {2012:[[65]*280], 2013:[[65]*280], 2014:[[65]*276], 2015:[[65]*270, [65]*6]}\n",
    "        expected_events2 = {2012:[[65]*280], 2013:[[65]*280], 2014:[[65]*276], 2015:[[65]*270, [65]*6]}\n",
    "        expected_events = tuple([expected_events1, expected_events2])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i]) \n",
    "\n",
    "    def test_ctf_handle_sim(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output\n",
    "        '''\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000131'\n",
    "        gauge1 = '421090'\n",
    "        gauge2 = '421022'\n",
    "        EWR = 'CF'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge1: [5]*123+[0]*5+[5]*232+[0]*5 + [0]*1+[5]*123+[0]*3+[5]*233+[0]*3+[5]*2 + [5]*123+[0]*5+[5]*232+[0]*5 + [5]*123+[0]*5+[5]*233+[5]*5,\n",
    "                         gauge2: [5]*123+[0]*5+[5]*232+[0]*5 + [0]*1+[5]*123+[0]*3+[5]*233+[0]*3+[5]*2 + [5]*123+[0]*5+[5]*232+[0]*5 + [5]*123+[5]*5+[5]*233+[0]*5\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.ctf_handle_sim(PU, gauge1, EWR, EWR_table, df_F, PU_df, allowance, climate)\n",
    "        # Setting up expected output - PU_df - and test\n",
    "        # Note the floats that get returned in the total event days series. This is because the totals of the two series are averaged.\n",
    "        data = {'CF_eventYears': [1,0,0,1], 'CF_numAchieved': [2,0,0,1], 'CF_numEvents': [2,0,0,1], 'CF_eventLength': [5.0,3.0,5.0,5.0], 'CF_totalEventDays': [10.0,6.0,10.0,5.0],\n",
    "                'CF_daysBetweenEvents': [[123, 232],[124,233],[125,232],[123,238]],\n",
    "                'CF_missingDays': [0,0,0,0], 'CF_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "        assert_frame_equal(PU_df, expected_PU_df) \n",
    "        # Setting up expected output - events - and test\n",
    "        expected_events1 = {2012:[[0]*5, [0]*5], 2013:[[0]*3, [0]*3], 2014:[[0]*5, [0]*5], 2015:[[0]*5]}\n",
    "        expected_events2 = {2012:[[0]*5, [0]*5], 2013:[[0]*3, [0]*3], 2014:[[0]*5, [0]*5], 2015:[[0]*5]}\n",
    "        expected_events = tuple([expected_events1, expected_events2])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "   \n",
    "    def test_complex_handle(self):\n",
    "        '''\n",
    "        1. Ensure all parts of the function generate expected output for OB2\n",
    "        2. Ensure all parts of the function generate expected output for OB3\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000253'\n",
    "        gauge = '409025'\n",
    "        EWR = 'OB2a_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge: [19000]*45+[9000]*105+[0]*215 + [15000]*45+[0]*8+[9000]*105+[0]*207 + [15000]*15+[0]*6+[15000]*15+[0]*6+[15000]*15+[0]*6+[9000]*55+[0]*6+[9000]*50+[0]*150+[16000]*41 + \\\n",
    "                                         [0]*6+[16000]*4+[0]*6+[9000]*105+[0]*95+[18000]*45+[9000]*105,\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.complex_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'OB2a_S_eventYears': [1,0,1,1], 'OB2a_S_numAchieved': [1,0,1,2], 'OB2a_S_numEvents': [1,0,1,2], 'OB2a_S_eventLength': [150.0,0.0,150.0,150.0], 'OB2a_S_totalEventDays': [150,0,150,300],\n",
    "                'OB2a_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'OB2a_S_missingDays': [0,0,0,0], 'OB2a_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "        assert_frame_equal(PU_df, expected_PU_df) \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[19000]*45+[9000]*105], 2013:[], 2014:[[15000]*15+[15000]*15+[15000]*15+[9000]*55+[9000]*50], 2015:[[16000]*41+[16000]*4+[9000]*105, [18000]*45+[9000]*105]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "        #-------------------------------------------------------------------------------------\n",
    "        # Test 2\n",
    "        # Set up input data\n",
    "        PU = 'PU_0000253'\n",
    "        gauge = '409025'\n",
    "        EWR = 'OB3a_S'\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        data_for_df_F = {'Date': pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d')),\n",
    "                         gauge:  [25000]*21+[15000]*90+[0]*254 + [25000]*21+[0]*8+[15000]*90+[0]*246 + [15000]*90+[0]*6+[25000]*21+[0]*8+[25000]*15+[0]*6+[25000]*6+[0]*6+[15000]*80+[0]*6+[15000]*10+[0]*94+[15000]*17 + \\\n",
    "                                         [0]*6+[15000]*73+[0]*6+[25000]*1+[25000]*20+[0]*149+[25000]*21+[15000]*90\n",
    "                        }\n",
    "        df_F = pd.DataFrame(data = data_for_df_F)\n",
    "        df_F = df_F.set_index('Date')\n",
    "        df_L = pd.DataFrame()\n",
    "        PU_df = pd.DataFrame()\n",
    "        allowance = {'minThreshold': 1.0, 'maxThreshold': 1.0, 'duration': 1.0, 'drawdown': 1.0}\n",
    "        climate = 'Standard - 1911 to 2018 climate categorisation'\n",
    "        # Pass input data to test function\n",
    "        PU_df, events = evaluate_EWRs.complex_handle(PU, gauge, EWR, EWR_table, df_F, PU_df, allowance)\n",
    "        # Setting up expected output - PU_df - and testing\n",
    "        data = {'OB3a_S_eventYears': [1,0,1,1], 'OB3a_S_numAchieved': [1,0,2,2], 'OB3a_S_numEvents': [1,0,2,2], 'OB3a_S_eventLength': [111.0,0.0,111.0,111.0], 'OB3a_S_totalEventDays': [111,0,222,222],\n",
    "                'OB3a_S_daysBetweenEvents': [[],[],[],[]],\n",
    "                'OB3a_S_missingDays': [0,0,0,0], 'OB3a_S_totalPossibleDays': [365,365,365,366]}\n",
    "        index = [2012, 2013, 2014,2015]\n",
    "        expected_PU_df = pd.DataFrame(index = index, data = data)\n",
    "        expected_PU_df.index = expected_PU_df.index.astype('object')\n",
    "        assert_frame_equal(PU_df, expected_PU_df) \n",
    "        # Setting up expected output - events - and testing\n",
    "        expected_events = {2012:[[25000]*21+[15000]*90], 2013:[], 2014:[[15000]*90+[25000]*21, [25000]*15+[25000]*6+[15000]*80+[15000]*10], 2015:[[15000]*17+[15000]*73+[25000]*21, [25000]*21+[15000]*90]}\n",
    "        expected_events = tuple([expected_events])\n",
    "        for index, tuple_ in enumerate(events):\n",
    "            for year in events[index]:\n",
    "                self.assertEqual(len(events[index][year]), len(expected_events[index][year]))\n",
    "                for i, event in enumerate(events[index][year]):\n",
    "                    self.assertListEqual(event, expected_events[index][year][i])\n",
    "\n",
    "Test = test_evaluate_EWRs_handling()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_ctf_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_lowflow_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_flow_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_cumulative_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_level_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_weirpool_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_nest_handle'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_flow_handle_multi'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_lowflow_handle_multi'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_ctf_handle_multi'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_cumulative_handle_multi'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_flow_handle_sim'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_lowflow_handle_sim'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_ctf_handle_sim'))\n",
    "suite.addTest(test_evaluate_EWRs_handling('test_complex_handle'))\n",
    "\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf205e8",
   "metadata": {},
   "source": [
    "#### Calculation functions + remaining functions in evaluate_EWRs module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "520d6b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".../home/pedro/.pyenv/versions/3.8.13/lib/python3.8/unittest/case.py:633: UserWarning: Parsing '31/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  method()\n",
      "./home/pedro/.pyenv/versions/3.8.13/lib/python3.8/unittest/case.py:633: UserWarning: Parsing '31/12/2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  method()\n",
      "................................\n",
      "----------------------------------------------------------------------\n",
      "Ran 36 tests in 1.411s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=36 errors=0 failures=0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test_evaluate_EWRs(unittest.TestCase):\n",
    "    def test_component_pull(self):\n",
    "        '''\n",
    "        1. Test correct value is pulled from EWR dataset\n",
    "        '''\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        gauge = '409025'\n",
    "        PU = 'PU_0000253'\n",
    "        EWR = 'SF1_P'\n",
    "        component = 'duration'\n",
    "        self.assertEqual(evaluate_EWRs.component_pull(EWR_table, gauge, PU, EWR, component), '10')\n",
    "        \n",
    "    def test_apply_correction(self):\n",
    "        '''\n",
    "        1. Test function that applies relaxation to parts of indicator\n",
    "        '''\n",
    "        info = 960\n",
    "        correction = 1.2\n",
    "        self.assertEqual(evaluate_EWRs.apply_correction(info, correction), 1152.0)\n",
    "        \n",
    "    def test_get_EWRs(self):\n",
    "        '''\n",
    "        1. Ensure requested parts of EWR are returned\n",
    "        '''\n",
    "        EWR_table, bad_EWRs = data_inputs.get_EWR_table()\n",
    "        PU = 'PU_0000283'\n",
    "        gauge = '410007'\n",
    "        EWR = 'SF1_P'\n",
    "        minThreshold_tolerance = (100 - 0)/100\n",
    "        maxThreshold_tolerance = (100 + 0)/100\n",
    "        duration_tolerance = (100 - 0)/100\n",
    "        drawdown_tolerance = (100 - 0)/100\n",
    "        allowance ={'minThreshold': minThreshold_tolerance, 'maxThreshold': maxThreshold_tolerance,\n",
    "                        'duration': duration_tolerance, 'drawdown': drawdown_tolerance}\n",
    "        components = ['SM', 'EM']\n",
    "        \n",
    "        expected = {'gauge': '410007', 'planning_unit': 'PU_0000283', 'EWR_code': 'SF1_P', 'start_day': None, 'start_month': 10, 'end_day': None, 'end_month':4}\n",
    "        self.assertEqual(evaluate_EWRs.get_EWRs(PU, gauge, EWR, EWR_table, allowance, components), expected)\n",
    "    \n",
    "    def test_mask_dates(self):\n",
    "        '''\n",
    "        This testing function will also be testing the functions get_month_mask, get_day_month_mask, and get_day_month_mask\n",
    "        1. Testing for no filtering (all year round EWR requirement)\n",
    "        2. Testing for a month subset\n",
    "        3. Testing for water year crossover EWR requirement\n",
    "        4. Testing for start day and end day within same month inclusion in the EWR requirement\n",
    "        5. Testing for start day and end day within different months inclusion in the EWR requirement:\n",
    "        '''\n",
    "        #------------ Dataframe to be passed to all testing functions here ----------#\n",
    "        \n",
    "        data = {'409102': list(range(0,3650,10)), '425012': list(range(0,3650,10))}\n",
    "        index = pd.date_range(start='1/1/2019', end='31/12/2019')\n",
    "        df = pd.DataFrame(data = data, index = index)\n",
    "        \n",
    "        #----------------------------------------------------------------------------#\n",
    "        # Test 1\n",
    "        EWR_info = {'start_day': None, 'end_day': None, 'start_month': 7, 'end_month': 6}\n",
    "        masked_7to6 = set(pd.date_range(start='1/1/2019', end='31/12/2019'))\n",
    "        self.assertEqual(evaluate_EWRs.mask_dates(EWR_info, df), masked_7to6)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # Test 2\n",
    "        EWR_info = {'start_day': None, 'end_day': None, 'start_month': 7, 'end_month': 9}\n",
    "        masked_7to9 = set(pd.date_range(start='2019-07-01', end='2019-09-30'))\n",
    "        self.assertEqual(evaluate_EWRs.mask_dates(EWR_info, df), masked_7to9)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # Test 3\n",
    "        EWR_info = {'start_day': None, 'end_day': None, 'start_month': 6, 'end_month': 8}\n",
    "        masked_6to8 = set(pd.date_range(start='2019-06-01', end='2019-08-31'))\n",
    "        self.assertEqual(evaluate_EWRs.mask_dates(EWR_info, df), masked_6to8)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # Test 4\n",
    "        EWR_info = {'start_day': 12, 'end_day': 28, 'start_month': 6, 'end_month': 6}\n",
    "        masked_612to628 = set(pd.date_range(start='2019-06-12', end='2019-06-28'))\n",
    "        self.assertEqual(evaluate_EWRs.mask_dates(EWR_info, df), masked_612to628)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # Test 5\n",
    "        EWR_info = {'start_day': 12, 'end_day': 18, 'start_month': 8, 'end_month': 9}\n",
    "        masked_812to918 = set(pd.date_range(start='2019-08-12', end='2019-09-18'))\n",
    "        self.assertEqual(evaluate_EWRs.mask_dates(EWR_info, df), masked_812to918)\n",
    "    def test_wateryear_daily(self):\n",
    "        '''\n",
    "        1. Testing non standard water year part of function\n",
    "        2. Testing standard water year part of function\n",
    "        '''\n",
    "        # Test 1\n",
    "        EWR_info = {'start_day': None, 'end_day': None, 'start_month': 5, 'end_month': 8}\n",
    "        data = {'409102': list(range(0,3650,10)), '425012': list(range(0,3650,10))}\n",
    "        index = pd.date_range(start='1/1/2019', end='31/12/2019')\n",
    "        df = pd.DataFrame(data = data, index = index)\n",
    "        expected_2018 = [2018]*120\n",
    "        expected_2019 = [2019]*245\n",
    "        expected_array = np.array(expected_2018 + expected_2019)\n",
    "        array = evaluate_EWRs.wateryear_daily(df, EWR_info)\n",
    "        self.assertTrue(np.array_equal(array, expected_array))\n",
    "        #-------------------------------------------------------\n",
    "        # Test 2\n",
    "        EWR_info = {'start_day': None, 'end_day': None, 'start_month': 7, 'end_month': 9}\n",
    "        data = {'409102': list(range(0,3650,10)), '425012': list(range(0,3650,10))}\n",
    "        index = pd.date_range(start='1/1/2019', end='31/12/2019')\n",
    "        df = pd.DataFrame(data = data, index = index)\n",
    "        expected_2018 = [2018]*181\n",
    "        expected_2019 = [2019]*184\n",
    "        expected_array = np.array(expected_2018 + expected_2019)\n",
    "        array = evaluate_EWRs.wateryear_daily(df, EWR_info)\n",
    "        self.assertTrue(np.array_equal(array, expected_array))\n",
    "    def test_which_wateryear(self):\n",
    "        '''\n",
    "        1. Testing for when there is an equal portion of the event falling in two water years\n",
    "        2. Testing for when there is a non-equal portion of the event falling within each water year\n",
    "        '''\n",
    "        # Test 1\n",
    "        i = 45\n",
    "        event = [10]*10\n",
    "        water_years = np.array([2018]*40+[2019]*10)\n",
    "        water_year = evaluate_EWRs.which_water_year(i, len(event), water_years)\n",
    "        self.assertEqual(water_year, 2019)\n",
    "        #----------------------------------\n",
    "        # Test 2\n",
    "        i = 42\n",
    "        event = [10]*9\n",
    "        water_years = np.array([2018]*40+[2019]*10)\n",
    "        water_year = evaluate_EWRs.which_water_year(i, len(event), water_years)\n",
    "        self.assertEqual(water_year, 2018)\n",
    "    def test_get_duration(self):\n",
    "        '''\n",
    "        1. Test for very dry duration for EWR where a very dry duration requirement exists\n",
    "        2. Test for very dry duration for EWR where a very dry duration requirement does not exists\n",
    "        '''\n",
    "        # Test 1\n",
    "        EWR_info = {'duration_VD': 2, 'duration': 5}\n",
    "        duration = evaluate_EWRs.get_duration('Very Dry', EWR_info)\n",
    "        self.assertEqual(duration, 2)\n",
    "        #-----------------------------\n",
    "        # Test 2\n",
    "        EWR_info = {'duration_VD': None, 'duration': 5}\n",
    "        duration = evaluate_EWRs.get_duration('Very Dry', EWR_info)\n",
    "        self.assertEqual(duration, 5)\n",
    "    def test_construct_event_dict(self):\n",
    "        '''\n",
    "        1. Test event dictionary with correct keys and values are returned\n",
    "        '''\n",
    "        water_years = [2018]*365+[2019]*365\n",
    "        all_events = evaluate_EWRs.construct_event_dict(water_years)\n",
    "        expected_result = {2018:[], 2019:[]}\n",
    "        self.assertEqual(all_events, expected_result)\n",
    "    def test_get_days_between(self):\n",
    "        '''\n",
    "        1. Testing low flow with more than 1 year interevent requirement\n",
    "        2. Testing low flow with less than 1 year of interevent requirement\n",
    "        3. Testing non low flow EWR with more than 1 year requirement\n",
    "        4. Testing for EWR with only a subset of the water year available\n",
    "        '''\n",
    "        # Test 1\n",
    "        no_events = {2012: [[735], [50], [2]], 2013: [[35], [50], [365]],\n",
    "                     2014: [[35], [50], [2]], 2015: [[35], [280], [2]]}\n",
    "        years_with_events = [0,0,0,1] # This will be used in the calculation\n",
    "        EWR = 'BF'\n",
    "        EWR_info = {'max_inter-event': 2}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        water_years = [2012]*365+[2013]*365+[2014]*365+[2015]*365\n",
    "        days_between = evaluate_EWRs.get_days_between(years_with_events, no_events, EWR, EWR_info, unique_water_years, water_years)\n",
    "        expected_days_between = [[], [], [], [1095]]\n",
    "        for i, v in enumerate(days_between):\n",
    "            self.assertListEqual(days_between[i], expected_days_between[i])\n",
    "        #--------------------------------------------------------------------\n",
    "        # Test 2\n",
    "        no_events = {2012: [[35], [50], [2]], 2013: [[35], [50], [2]],\n",
    "                     2014: [[35], [50], [2]], 2015: [[35], [50], [2]]}\n",
    "        years_with_events = [0,0,0,1] #This will be ignored in this calculation\n",
    "        EWR = 'BF'\n",
    "        EWR_info = {'max_inter-event': 0.04} # Equates to about 14-15 days\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        water_years = [2012]*365+[2013]*365+[2014]*365+[2015]*365\n",
    "        days_between = evaluate_EWRs.get_days_between(years_with_events, no_events, EWR, EWR_info, unique_water_years, water_years)\n",
    "        expected_days_between = [[35, 50], [35, 50], [35, 50], [35, 50]]\n",
    "        for i, v in enumerate(days_between):\n",
    "            self.assertListEqual(days_between[i], expected_days_between[i])\n",
    "        #--------------------------------------------------------------------\n",
    "        # Test 3\n",
    "        no_events = {2012: [[35], [50], [2]], 2013: [[35], [50], [2]],\n",
    "                     2014: [[35], [50], [2]], 2015: [[735], [2]]}\n",
    "        years_with_events = [0,1,0,0] #This will be ignored in this calculation\n",
    "        EWR = 'LF'\n",
    "        EWR_info = {'max_inter-event': 2}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        water_years = [2012]*365+[2013]*365+[2014]*365+[2015]*365\n",
    "        days_between = evaluate_EWRs.get_days_between(years_with_events, no_events, EWR, EWR_info, unique_water_years, water_years)\n",
    "        expected_days_between = [[], [], [], [735]]\n",
    "        for i, v in enumerate(days_between):\n",
    "            self.assertListEqual(days_between[i], expected_days_between[i])\n",
    "        #--------------------------------------------------------------------\n",
    "        # Test 4\n",
    "        no_events = {2012: [[35], [122], [2]], 2013: [[35], [50], [2]],\n",
    "                     2014: [[35], [50], [2]], 2015: [[730], [50], [121]]}\n",
    "        years_with_events = [0,0,0,1] #This will be ignored in this calculation\n",
    "        EWR = 'LF'\n",
    "        EWR_info = {'max_inter-event': 2}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        water_years = [2012]*365+[2013]*365+[2014]*365+[2015]*365\n",
    "        days_between = evaluate_EWRs.get_days_between(years_with_events, no_events, EWR, EWR_info, unique_water_years, water_years)\n",
    "        expected_days_between = [[], [], [], [730]]\n",
    "        for i, v in enumerate(days_between):          \n",
    "            self.assertListEqual(days_between[i], expected_days_between[i])\n",
    "    def test_get_event_years(self):\n",
    "        '''\n",
    "        Year 1: check 1 is returned when there are 3 events with 2 required per year\n",
    "        Year 2: check 0 is returned when there is 1 event with 2 required per year\n",
    "        Year 3: check 1 is returned when there are 4 events with 2 required per year\n",
    "        Year 4: check 0 is returned when there are 0 events with 2 required per year\n",
    "        '''\n",
    "        EWR_info = {'events_per_year': 2}\n",
    "        events = {2012: [[5]*5, [10]*5, [20*8]], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20*8], [20*8]], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        durations = [5,5,5,5]\n",
    "        min_events = [5,5,5,5]\n",
    "        event_years = evaluate_EWRs.get_event_years(EWR_info, events, unique_water_years, durations, min_events)\n",
    "        expected_event_years = [1,0,1,0]\n",
    "        self.assertEqual(event_years, expected_event_years)\n",
    "    def test_get_achievements(self):\n",
    "        '''\n",
    "        1. Testing 1 event per year requirement with four unique events per year ranges\n",
    "        2. Testing 2 events per year requirement with four unique events per year ranges\n",
    "        '''\n",
    "        EWR_info = {'events_per_year': 1}\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        durations = [5,5,5,5]\n",
    "        min_events = [5,5,5,5]\n",
    "        num_events = evaluate_EWRs.get_achievements(EWR_info, events, unique_water_years, durations, min_events)\n",
    "        expected_num_events = [3,1,4,0]\n",
    "        self.assertEqual(num_events, expected_num_events)\n",
    "        #-------------------------------------------------\n",
    "        # Test 2\n",
    "        EWR_info = {'events_per_year': 2}\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        durations = [5,5,5,5]\n",
    "        min_events = [5,5,5,5]\n",
    "        num_events = evaluate_EWRs.get_achievements(EWR_info, events, unique_water_years, durations, min_events)\n",
    "        expected_num_events = [1,0,2,0]\n",
    "        self.assertEqual(num_events, expected_num_events)\n",
    "    def test_get_number_events(self):\n",
    "        '''\n",
    "        1. Testing 1 event per year requirement with four unique events per year ranges\n",
    "        2. Testing 2 events per year requirement with four unique events per year ranges\n",
    "        '''\n",
    "        # Test 1\n",
    "        EWR_info = {'events_per_year': 1}\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        durations = [5,5,5,5]\n",
    "        min_events = [5,5,5,5]\n",
    "        num_events = evaluate_EWRs.get_number_events(EWR_info, events, unique_water_years, durations, min_events)\n",
    "        expected_num_events = [3,1,4,0]\n",
    "        self.assertEqual(num_events, expected_num_events)\n",
    "        #--------------------------------------------------\n",
    "        # Test 2\n",
    "        EWR_info = {'events_per_year': 2}\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        durations = [5,5,5,5]\n",
    "        min_events = [5,5,5,5]\n",
    "        num_events = evaluate_EWRs.get_number_events(EWR_info, events, unique_water_years, durations, min_events)\n",
    "        expected_num_events = [3,1,4,0]\n",
    "        self.assertEqual(num_events, expected_num_events)\n",
    "    def test_get_average_event_length(self):\n",
    "        '''\n",
    "        1. Test yearly average event length for test years with between 0 and 4 total events\n",
    "        '''\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        average_length = evaluate_EWRs.get_average_event_length(events, unique_water_years)\n",
    "        expected_average_length = [6,20,6.5,0]\n",
    "        self.assertEqual(average_length, expected_average_length)\n",
    "    def test_get_total_days(self):\n",
    "        '''\n",
    "        1. Test total yearly event length for test years with between 0 and 4 total events\n",
    "        '''\n",
    "        events = {2012: [[5]*5, [10]*5, [20]*8], 2013: [[50]*20],\n",
    "                  2014: [[5]*5, [10]*5, [20]*8, [20]*8], 2015: []}\n",
    "        unique_water_years = [2012, 2013, 2014, 2015]\n",
    "        total_days = evaluate_EWRs.get_total_days(events, unique_water_years)\n",
    "        expected_total_days = [18,20,26,0]\n",
    "        self.assertEqual(total_days, expected_total_days)\n",
    "    def test_get_data_gap(self):\n",
    "        '''\n",
    "        1. Check event gaps are accurate\n",
    "        '''\n",
    "        data = {'409102': list(range(0,3650,10)), '425012': list(range(0,3650,10))}\n",
    "        index = pd.date_range(start='1/1/2019', end='31/12/2019')\n",
    "        df = pd.DataFrame(data = data, index = index)\n",
    "        df.iloc[0:4] = None\n",
    "        df.iloc[57] = np.nan\n",
    "        unique_water_years = [2018]*181+[2019]*184\n",
    "        gauge = '409102'\n",
    "        missing_list = evaluate_EWRs.get_data_gap(df, unique_water_years, gauge)\n",
    "        expected_missing = [5,0]\n",
    "        self.assertEqual(missing_list, expected_missing)\n",
    "    def test_check_flow(self):\n",
    "        '''\n",
    "        1. Test flow threshold passes and event requirements just met\n",
    "        2. TO-TEST: flow threshold below but event requirement passed\n",
    "        3. TO-TEST: event requirements failed but there is some gap track remaining\n",
    "        4. TO-TEST: flow threshold failed and event requirements not met\n",
    "        '''\n",
    "        # Set up inputs parameters and pass to test function\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'gap_tolerance': 0, 'min_event':10}\n",
    "        iteration = 50\n",
    "        flow = 5\n",
    "        event = [5]*9\n",
    "        all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                      2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        no_event = 50\n",
    "        all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                         2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        gap_track = 0\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*365)\n",
    "        total_event = 9\n",
    "        event, all_events, no_event, all_no_events, gap_track, total_event = evaluate_EWRs.flow_check(EWR_info, iteration, flow, event, all_events, no_event, all_no_events, gap_track, water_years, total_event)\n",
    "        # Set up expected results and test\n",
    "        expected_event = [5]*10\n",
    "        expected_all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                               2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        expected_no_event = 51\n",
    "        expected_all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                                  2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        expected_gap_track = 0\n",
    "        expected_total_event = 10\n",
    "        self.assertEqual(event,expected_event)\n",
    "        for year in all_events:\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        self.assertEqual(no_event, expected_no_event)\n",
    "        self.assertDictEqual(all_no_events, expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(gap_track, expected_gap_track)\n",
    "        self.assertEqual(total_event, expected_total_event)\n",
    "        \n",
    "    def test_lowflow_check(self):\n",
    "        '''\n",
    "        1. Test flow passes and event requirement just met\n",
    "        2. TO-TEST: flow threshold below but event requirement passed\n",
    "        3. TO-TEST: flow threshold failed and event requirements failed\n",
    "        '''\n",
    "        # Set up variables for all tests\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20}\n",
    "        flow = 5\n",
    "        water_year = 2015\n",
    "        event = [5]*9\n",
    "        iteration = 365+365+365+100\n",
    "        all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                      2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        no_event = 0\n",
    "        all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                         2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*365)\n",
    "        event, all_events, no_event, all_no_events = evaluate_EWRs.lowflow_check(EWR_info, iteration, flow, event, all_events, no_event, all_no_events, water_years)\n",
    "        # Set up expected output and test\n",
    "        expected_event = [5]*10\n",
    "        expected_all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                               2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        expected_no_event = 0\n",
    "        expected_all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                                  2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        self.assertEqual(event,expected_event)\n",
    "        for year in all_events:\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        self.assertEqual(no_event, expected_no_event)\n",
    "        self.assertDictEqual(all_no_events, expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "    def test_ctf_check(self):\n",
    "        '''\n",
    "        1. flow threshold fails but event meets requirements\n",
    "        2. TO-TEST: flow threshold passed\n",
    "        3. TO-TEST: flow threshold failed but no event recorded\n",
    "        '''\n",
    "        # Set up input variables and pass to test function\n",
    "        EWR_info = {'min_flow': 0, 'max_flow': 1}\n",
    "        flow = 2\n",
    "        event = [0]*9\n",
    "        iteration = 365+365+365+100\n",
    "        all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                      2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        no_event = 10\n",
    "        all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                         2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*365)\n",
    "\n",
    "        event, all_events, no_event, all_no_events = evaluate_EWRs.ctf_check(EWR_info, iteration, flow, event, all_events, no_event, all_no_events, water_years)\n",
    "        # Set up expected outputs and test\n",
    "        expected_event = []\n",
    "        expected_all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50],\n",
    "                               2014:[[10]*10, [15]*15, [10]*20], 2015:[[0]*9]}\n",
    "        expected_no_event = 1\n",
    "        expected_all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                                  2014:[[400], [2], [25]], 2015:[[450], [10]]}\n",
    "        self.assertEqual(event,expected_event)\n",
    "        for year in all_events:\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        self.assertEqual(no_event, expected_no_event)\n",
    "        for year in all_no_events:\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "    def test_level_check(self):\n",
    "        '''\n",
    "        1. Test level threshold fails but event requirement passed\n",
    "        2. TO-TEST: test level threshold passes and event requirement met\n",
    "        3. TO-TEST: level threshold fails and event requirement failed\n",
    "        '''\n",
    "        # Set up input variables\n",
    "        EWR_info = {'min_level': 10, 'max_level':20, 'duration': 5, 'drawdown_rate':0.04}\n",
    "        level = 5\n",
    "        level_change = 0.04\n",
    "        water_year = 2015\n",
    "        event = [10]*5\n",
    "        iteration = 365+365+365+100\n",
    "        all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                      2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        no_event = 15\n",
    "        all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                         2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*365)\n",
    "\n",
    "        event, all_events, no_event, all_no_events = evaluate_EWRs.level_check(EWR_info, iteration, level, level_change, event, all_events, no_event, all_no_events, water_years)\\\n",
    "        # Expected results - TEST 1: #\n",
    "        expected_event = []\n",
    "        expected_all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                               2014:[[10]*10, [15]*15, [10]*20], 2015:[[10]*5]}\n",
    "        expected_no_event = 1\n",
    "        expected_all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                                  2014:[[400], [2], [25]], 2015:[[450], [10]]}\n",
    "        self.assertEqual(event,expected_event)\n",
    "        for year in all_events:\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        self.assertEqual(no_event, expected_no_event)\n",
    "        self.assertDictEqual(all_no_events, expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "                \n",
    "    def test_flow_check_sim(self):\n",
    "        '''\n",
    "        1. flow threshold below for both sites but event requirement passed\n",
    "        2. TO-TEST: Test flow threshold passes for both sites and event requirements just met\n",
    "        3. TO-TEST: event requirements failed but there is some gap track remaining\n",
    "        4. TO-TEST: flow threshold failed and event requirements not met\n",
    "        5. TO-TEST: flow threshold above for one site and below for another, event requirements not met\n",
    "        '''\n",
    "        # Set up input parameters and send to test function\n",
    "        iteration = 370\n",
    "        EWR_info1 = {'min_flow': 10, 'max_flow': 20, 'min_event': 5, 'gap_tolerance': 0}\n",
    "        EWR_info2 = {'min_flow': 10, 'max_flow': 20, 'min_event': 5, 'gap_tolerance': 0}\n",
    "        flow1 = 5\n",
    "        flow2 = 7\n",
    "        event = [10]*5\n",
    "        total_event = 5\n",
    "        all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50], \n",
    "                      2014:[[10]*10, [15]*15, [10]*20], 2015:[]}\n",
    "        no_event = 25\n",
    "        all_no_events = {2012:[[25], [2]], 2013:[[250]],\n",
    "                         2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*365)\n",
    "        gap_track = 0\n",
    "        event, all_events, no_event, all_no_events, gap_track, total_event = evaluate_EWRs.flow_check_sim(iteration, EWR_info1, EWR_info2, water_years, flow1, flow2, event, all_events, no_event, all_no_events, gap_track, total_event)\n",
    "        # Set up expected results and test\n",
    "        expected_event = []\n",
    "        expected_all_events = {2012:[[10]*10, [15]*12], 2013:[[10]*50, [10]*5],\n",
    "                               2014:[[10]*10, [15]*15, [10]*20], 2015:[[10]*5]}\n",
    "        expected_no_event = 1\n",
    "        expected_all_no_events = {2012:[[25], [2]], 2013:[[250], [20]],\n",
    "                                  2014:[[400], [2], [25]], 2015:[[450]]}\n",
    "        expected_gap_track = 0\n",
    "        expected_total_event = 0\n",
    "        self.assertEqual(gap_track, expected_gap_track)\n",
    "        self.assertEqual(event,expected_event)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        self.assertEqual(no_event, expected_no_event)\n",
    "        self.assertDictEqual(all_no_events, expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "                \n",
    "    def test_flow_calc(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows (TO-TEST: flows overlapping water year edge)\n",
    "        2. TO-TEST: constrain timing window\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        flows = np.array([0]*355+[10]*10 + [0]*355+[10]*10 + [0]*355+[10]*10 + [0]*355+[10]*10+[10]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data        \n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: [[10]*11]}\n",
    "        expected_all_no_events = {2012: [[355]], 2013: [[355]], 2014: [[355]], 2015: [[355]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send inputs to test function and test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.flow_calc(EWR_info, flows, water_years, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_lowflow_calc(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows\n",
    "        2. Constrain timing window and test functions ability to identify and save all events and event gaps for series of flows\n",
    "        '''\n",
    "        # Test 1\n",
    "        # set up input data \n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'min_event':1, 'duration': 300, 'duration_VD': 10}\n",
    "        flows = np.array([5]*295+[0]*25+[10]*45 + [0]*355+[5000]*10 + [0]*355+[10]*10 + [5]*295+[0]*25+[10]*45+[10]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Wet']*365 + ['Very Dry']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[5]*295, [10]*45], 2013: [], 2014: [[10]*10], 2015: [[5]*295, [10]*46]}\n",
    "        expected_all_no_events = {2012: [[25]], 2013: [], 2014: [[720]], 2015: [[25]]}\n",
    "        expected_durations = [300,300,10,300] # adding in a very dry year climate year\n",
    "        expected_min_events = [1,1,1,1]\n",
    "        # Send inputs to test function and test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.lowflow_calc(EWR_info, flows, water_years, climates, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        #------------------------------------------------\n",
    "        # Test 2\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'min_event':1, 'duration': 10, \n",
    "                    'duration_VD': 5, 'start_month': 7, 'end_month': 12, 'start_day': None, 'end_day': None}\n",
    "        flows = np.array([10]*5+[0]*35+[5]*5+[0]*295+[0]*25 + [0]*355+[5]*10 + [10]*10+[0]*355 + [5]*295+[0]*25+[10]*45+[10]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Wet']*365 + ['Very Dry']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = masked_dates[((masked_dates.month >= 7) & (masked_dates.month <= 12))] # Just want the dates in the date range\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*5, [5]*5], 2013: [], 2014: [[10]*10], 2015: [[5]*184]}\n",
    "        expected_all_no_events = {2012: [[35]], 2013: [[685]], 2014: [[355]], 2015: [[181]]}\n",
    "        expected_durations = [10,10,5,10] # adding in a very dry year climate year\n",
    "        expected_min_events = [1,1,1,1]\n",
    "        # Send to test function and test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.lowflow_calc(EWR_info, flows, water_years, climates, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "\n",
    "    def test_ctf_calc(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, \n",
    "           ensuring events are cut off at the end of the water year even though dates are not constrained\n",
    "        2. Constrain timing window and test functions ability to identify and save all events and event gaps for series of flows\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 0, 'max_flow': 1, 'min_event':5, 'duration': 20, 'duration_VD': 10}\n",
    "        flows = np.array([5]*295+[0]*25+[10]*45 + [20]*355+[5000]*5+[0]*5 + [0]*355+[10]*10 + [1]*295+[20]*25+[0]*45+[0]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Wet']*365 + ['Very Dry']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[0]*25], 2013: [[0]*5], 2014: [[0]*355], 2015: [[1]*295, [0]*46]}\n",
    "        expected_all_no_events = {2012: [[295]], 2013: [[405]], 2014: [], 2015: [[10], [25]]}\n",
    "        expected_durations = [20,20,10,20] # adding in a very dry year climate year\n",
    "        expected_min_events = [5,5,5,5]\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.ctf_calc(EWR_info, flows, water_years, climates, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        #--------------------------------------------------\n",
    "        # Test 2\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'min_event':1, 'duration': 10,\n",
    "                    'duration_VD': 5, 'start_month': 7, 'end_month': 12, 'start_day': None, 'end_day': None}\n",
    "        flows = np.array([10]*5+[0]*35+[5]*5+[0]*295+[0]*25 + [0]*355+[5]*10 + [10]*10+[0]*355 + [5]*295+[0]*25+[10]*45+[10]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Wet']*365 + ['Very Dry']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = masked_dates[((masked_dates.month >= 7) & (masked_dates.month <= 12))] # Just want the dates in the date range\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*5, [5]*5], 2013: [], 2014: [[10]*10], 2015: [[5]*184]}\n",
    "        expected_all_no_events = {2012: [[35]], 2013: [[685]], 2014: [[355]], 2015: [[181]]}\n",
    "        expected_durations = [10,10,5,10] # adding in a very dry year climate year\n",
    "        expected_min_events = [1,1,1,1]\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.lowflow_calc(EWR_info, flows, water_years, climates, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "\n",
    "    def test_ctf_calc_anytime(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, ensure events overlapping water year edges are registered\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 0, 'max_flow': 1, 'min_event':5, 'duration': 20, 'duration_VD': 10}\n",
    "        flows = np.array([5]*295+[0]*25+[10]*45 + [20]*355+[5000]*5+[0]*5 + [0]*355+[10]*10 + [1]*295+[20]*25+[0]*45+[0]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Wet']*365 + ['Very Dry']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[0]*25], 2013: [], 2014: [[0]*360], 2015: [[1]*295, [0]*46]}\n",
    "        expected_all_no_events = {2012: [[295]], 2013: [[405]], 2014: [], 2015: [[10], [25]]}\n",
    "        expected_durations = [20,20,10,20] # adding in a very dry year climate year\n",
    "        expected_min_events = [5,5,5,5]\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.ctf_calc_anytime(EWR_info, flows, water_years, climates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_flow_calc_anytime(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, ensure events overlapping water year edges are registered\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        flows = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[0]*350+[10]*10+[10]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [], 2014: [[10]*20, [10]*15], 2015: [[10]*11]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [[345]], 2015: [[350]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.flow_calc_anytime(EWR_info, flows, water_years)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_lake_calc(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of lake levels, \n",
    "           ensuring events are cut off at the end of the water year even though dates are not constrained\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_level': 50, 'max_level': 60, 'duration': 10, 'min_event': 10, 'drawdown_rate': 0.04}\n",
    "        levels = np.array([0]*350+[50]*10+[0]*5 + [0]*355+[61]*10 + [50]*10+[0]*345+[50]*10 + [50]*5+[0]*350+[50]*10+[50]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[50]*10], 2013: [], 2014: [[50]*10], 2015: [[50]*11]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [], 2014: [[725]], 2015: [[355]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.lake_calc(EWR_info, levels, water_years, dates, masked_dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "\n",
    "    def test_cumulative_calc(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, \n",
    "           ensuring events are cut off at the end of the water year even though dates are not constrained\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_volume': 100, 'min_flow': 50, 'min_event': 2, 'duration': 2}\n",
    "        flows = np.array([0]*350+[10]*10+[20]*5 + [0]*360+[100]*5 + [75]*1+[25]*1+[0]*353+[50]*10 + [50]*2+[0]*362+[49]*1+[100]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [], \n",
    "                               2013: [[100], [100]*2, [100]*2], \n",
    "                               2014: [[50]*2, [50]*2, [50]*2, [50]*2, [50]*2], \n",
    "                               2015: [[50]*2, [100]*1]}\n",
    "        expected_all_no_events = {2012: [], 2013: [[724]], 2014: [[355]], 2015: [[362]]}\n",
    "        expected_durations = [2]*4\n",
    "        expected_min_events = [2]*4\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.cumulative_calc(EWR_info, flows, water_years, dates, masked_dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "        \n",
    "    def test_cumulative_calc_anytime(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, \n",
    "           ensuring events crossing water years are identified and registered\n",
    "               - Test event crossing water years\n",
    "               - Test event on final day of series\n",
    "               - TO-TEST: event on first day of series\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_volume': 100, 'min_flow': 50, 'min_event': 2, 'duration': 2}\n",
    "        flows = np.array([0]*350+[10]*14+[50]*1 + [50]*1+[0]*358+[100]*6 + [75]*1+[25]*1+[0]*353+[50]*10 + [50]*2+[0]*362+[49]*1+[100]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        # Set up expected outputs\n",
    "        expected_all_events = {2012: [], \n",
    "                               2013: [[50]*2, [100]*1, [100]*2, [100]*2], \n",
    "                               2014: [[100,75], [50]*2, [50]*2, [50]*2, [50]*2, [50]*2], \n",
    "                               2015: [[50]*2, [100]*1]}\n",
    "        expected_all_no_events = {2012: [], 2013: [[364], [357]], 2014: [[354]], 2015: [[362]]}\n",
    "        expected_durations = [2]*4\n",
    "        expected_min_events = [2]*4\n",
    "        # Send inputs to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.cumulative_calc_anytime(EWR_info, flows, water_years)       \n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_nest_calc_weirpool(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows and levels, ensure events cannot overlap water years. Other tests:\n",
    "            - check if event exluded when flow requirement is passed but the level requirement is not passed\n",
    "            - TO-TEST: check if event exluded when flow requirement is not passed but the level requirement is passed\n",
    "            - TO-TEST: check if event is excluded when flow and level requirements are passed but the drawdown rate is exceeded\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'drawdown_rate': 0.04, 'min_event': 10, 'duration': 10}\n",
    "        flows = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[0]*351+[10]*10)\n",
    "        levels = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*9+[1]*1 + [10]*5+[0]*351+[10]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: [[10]*10]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[711]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.nest_calc_weirpool(EWR_info, flows, levels, water_years, dates, masked_dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_nest_calc_percent(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, ensure events cannot overlap water years. Other tests:\n",
    "            - check if event exluded when flow requirement is passed but the drawdown rate is exceeded\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'drawdown_rate': '10%', 'min_event': 10, 'duration': 10}\n",
    "        flows = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*9+[8]*1 + [10]*9+[9]*1+[0]*346+[10]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: [[10]*9+[9]*1, [10]*10]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[355], [346]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.nest_calc_percent(EWR_info, flows, water_years, dates, masked_dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_nest_calc_percent_trigger(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows, ensure events cannot overlap water years. Other tests:\n",
    "            - check if event exluded when flow requirement is passed but the drawdown rate is exceeded\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'drawdown_rate': '10%', 'min_event': 10, 'duration': 10, 'trigger_day': 15, 'trigger_month': 10}\n",
    "        flows = np.array([0]*106+[11]*1+[10]*9+[0]*249 + [0]*106+[9]*1+[10]*9+[0]*249 + [0]*106+[10]*9+[9]*1+[0]*249 + [0]*106+[10]*9+[8]*1+[0]*250)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[11]*1+[10]*9], 2013: [[9]*1+[10]*9], 2014: [[10]*9+[9]*1], 2015: []}\n",
    "        expected_all_no_events = {2012: [[106]], 2013: [[355]], 2014: [[355]], 2015: [[615]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send input data to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.nest_calc_percent_trigger(EWR_info, flows, water_years, dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_weirpool_calc(self):\n",
    "        '''\n",
    "        1. Test weirpool drawdown\n",
    "        2. Test weirpool raising\n",
    "        \n",
    "        For the above two tests: Test functions ability to identify and save all events and event gaps for series of flows and levels, ensure events cannot overlap water years. Other tests:\n",
    "            - check if event exluded when flow requirement is passed but the level requirement is not passed\n",
    "            - check if event is excluded when flow and level requirements are passed but the drawdown rate is exceeded\n",
    "            - TO-TEST: check if event exluded when flow requirement is not passed but the level requirement is passed\n",
    "        '''\n",
    "        # Test 1\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'min_level': 5, 'max_level': 10, 'drawdown_rate': 0.04, 'min_event': 10, 'duration': 10}\n",
    "        flows = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[8]*5+[0]*346+[10]*10)\n",
    "        levels = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*9+[1]*1 + [11]*5+[10]*5+[0]*346+[11]*1+[10]*9)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: []}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[721]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        weirpool_type = 'falling'\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.weirpool_calc(EWR_info, flows, levels, water_years, weirpool_type, dates, masked_dates)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        #--------------------------------------------------\n",
    "        # Test 2\n",
    "        # Set up input data\n",
    "        EWR_info = {'min_flow': 5, 'max_flow': 20, 'min_level': 10, 'max_level': 20, 'drawdown_rate': 0.04, 'min_event': 10, 'duration': 10}\n",
    "        flows = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[8]*5+[0]*346+[10]*10)\n",
    "        levels = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*9+[1]*1 + [11]*5+[10.96]*5+[0]*346+[10]*9+[9.96]*1)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: [[10]*5+[8]*5]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[355], [356]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_event = [10]*4\n",
    "        weirpool_type = 'raising'\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.weirpool_calc(EWR_info, flows, levels, water_years, weirpool_type, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_flow_calc_anytime_sim(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows\n",
    "            - Check events can span multiple water years\n",
    "            - Check event not registered when only one site meets flow requirement\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info1 = {'min_flow': 10, 'max_flow': 20, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        EWR_info2 = {'min_flow': 20, 'max_flow': 30, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        flows1 = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[0]*351+[10]*10)\n",
    "        flows2 = np.array([0]*350+[30]*10+[0]*5 + [0]*355+[30]*10 + [30]*10+[0]*345+[10]*10 + [10]*10+[0]*346+[30]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [], 2014: [[10]*20], 2015: [[10]*10]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[711]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.flow_calc_anytime_sim(EWR_info1, EWR_info2, flows1, flows2, water_years)\n",
    "#         print(all_events)\n",
    "#         print(expected_all_events)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "#         print(all_no_events)\n",
    "#         print(expected_all_no_events)\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "\n",
    "    def test_flow_calc_sim(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows\n",
    "            - Check events cannot span multiple water years\n",
    "            - Check event not registered when only one site meets flow requirement\n",
    "            - TO-TEST: constrain months of water year and repeat test\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info1 = {'min_flow': 10, 'max_flow': 20, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        EWR_info2 = {'min_flow': 20, 'max_flow': 30, 'gap_tolerance': 0, 'min_event':10, 'duration': 10}\n",
    "        flows1 = np.array([0]*350+[10]*10+[0]*5 + [0]*355+[10]*10 + [10]*10+[0]*345+[10]*10 + [10]*5+[0]*351+[10]*10)\n",
    "        flows2 = np.array([0]*350+[30]*10+[0]*5 + [0]*355+[30]*10 + [30]*10+[0]*345+[10]*10 + [10]*10+[0]*346+[30]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events = {2012: [[10]*10], 2013: [[10]*10], 2014: [[10]*10], 2015: [[10]*10]}\n",
    "        expected_all_no_events = {2012: [[350]], 2013: [[360]], 2014: [], 2015: [[711]]}\n",
    "        expected_durations = [10]*4\n",
    "        expected_min_events = [10]*4\n",
    "        # Send to test function and then test\n",
    "        all_events, all_no_events, durations, min_events = evaluate_EWRs.flow_calc_sim(EWR_info1, EWR_info2, flows1, flows2, water_years, dates, masked_dates)\n",
    "        for year in all_events:\n",
    "            self.assertEqual(len(all_events[year]), len(expected_all_events[year]))\n",
    "            for i, event in enumerate(all_events[year]):\n",
    "                self.assertListEqual(event, expected_all_events[year][i])\n",
    "        for year in all_no_events:\n",
    "            self.assertEqual(len(all_no_events[year]), len(expected_all_no_events[year]))\n",
    "            for i, no_event in enumerate(all_no_events[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "    def test_lowflow_calc_sim(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows\n",
    "            - Test to ensure it does not matter event sequencing at each site, as long as minimum day duration is met for each year, event should be registered\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info1 = {'min_flow': 10, 'max_flow': 20, 'min_event': 1, 'duration': 10, 'duration_VD': 5}\n",
    "        EWR_info2 = {'min_flow': 20, 'max_flow': 30, 'min_event': 1, 'duration': 10, 'duration_VD': 5}\n",
    "        flows1 = np.array([10]*1+[0]*350+[10]*9+[0]*5 + [0]*360+[10]*5 + [10]*10+[0]*345+[10]*10 + [8]*5+[0]*351+[10]*10)\n",
    "        flows2 = np.array([25]*1+[0]*350+[30]*9+[0]*5 + [0]*360+[30]*5 + [30]*10+[0]*345+[10]*10 + [18]*10+[0]*346+[30]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Dry']*365 +['Very Wet']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected output data\n",
    "        expected_all_events1 = {2012: [[10]*1, [10]*9], 2013: [[10]*5], 2014: [[10]*10, [10]*10], 2015: [[10]*10]}\n",
    "        expected_all_events2 = {2012: [[25]*1, [30]*9], 2013: [[30]*5], 2014: [[30]*10], 2015: [[30]*10]}\n",
    "        expected_all_no_events1 = {2012: [[350]], 2013: [[365]], 2014: [[345]], 2015: [[356]]}\n",
    "        expected_all_no_events2 = {2012: [[350]], 2013: [[365]], 2014: [], 2015: [[711]]}\n",
    "        expected_durations = [10,5,10,10]\n",
    "        expected_min_events = [1,1,1,1]\n",
    "        # Send inputs to function and then test:\n",
    "        all_events1, all_events2, all_no_events1, all_no_events2, durations, min_events = evaluate_EWRs.lowflow_calc_sim(EWR_info1, EWR_info2, flows1, flows2, water_years, climates, dates, masked_dates)\n",
    "#         print(all_events1)\n",
    "#         print(expected_all_events1)\n",
    "        for year in all_events1:\n",
    "            self.assertEqual(len(all_events1[year]), len(expected_all_events1[year]))\n",
    "            for i, event in enumerate(all_events1[year]):\n",
    "                self.assertListEqual(event, expected_all_events1[year][i])\n",
    "#         print(all_events2)\n",
    "#         print(expected_all_events2)\n",
    "        for year in all_events2:\n",
    "            self.assertEqual(len(all_events2[year]), len(expected_all_events2[year]))\n",
    "            for i, event in enumerate(all_events2[year]):\n",
    "                self.assertListEqual(event, expected_all_events2[year][i])\n",
    "#         print(all_no_events1)\n",
    "#         print(expected_all_no_events1)\n",
    "        for year in all_no_events1:\n",
    "            self.assertEqual(len(all_no_events1[year]), len(expected_all_no_events1[year]))\n",
    "            for i, no_event in enumerate(all_no_events1[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events1[year][i])\n",
    "#         print(all_no_events2)\n",
    "#         print(expected_all_no_events2)\n",
    "        for year in all_no_events2:\n",
    "            self.assertEqual(len(all_no_events2[year]), len(expected_all_no_events2[year]))\n",
    "            for i, no_event in enumerate(all_no_events2[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events2[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "        self.assertEqual(min_events, expected_min_events)\n",
    "        \n",
    "        \n",
    "    def test_ctf_calc_sim(self):\n",
    "        '''\n",
    "        1. Test functions ability to identify and save all events and event gaps for series of flows\n",
    "        '''\n",
    "        # Set up input data\n",
    "        EWR_info1 = {'min_flow': 0, 'max_flow': 1, 'min_event': 10, 'duration': 10, 'duration_VD': 5}\n",
    "        EWR_info2 = {'min_flow': 0, 'max_flow': 1, 'min_event': 10, 'duration': 10, 'duration_VD': 5}\n",
    "        flows1 = np.array([10]*1+[0]*350+[10]*9+[1]*5 + [0]*360+[10]*5 + [10]*10+[0]*345+[10]*1+[1]*9 + [8]*5+[10]*351+[0]*10)\n",
    "        flows2 = np.array([10]*1+[0]*350+[10]*9+[1]*5 + [0]*360+[10]*5 + [10]*10+[0]*345+[10]*1+[1]*9 + [8]*5+[10]*351+[0]*10)\n",
    "        water_years = np.array([2012]*365 + [2013]*365 + [2014]*365 + [2015]*366)\n",
    "        climates = np.array(['Wet']*365 + ['Very Dry']*365 +['Very Wet']*365 + ['Dry']*366)\n",
    "        dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        masked_dates = pd.date_range(start= datetime.strptime('2012-07-01', '%Y-%m-%d'), end = datetime.strptime('2016-06-30', '%Y-%m-%d'))\n",
    "        # Set up expected outputs\n",
    "        expected_all_events1 = {2012: [[0]*350, [1]*5], 2013: [[0]*360], 2014: [[0]*345, [1]*9], 2015: [[0]*10]}\n",
    "        expected_all_events2 = {2012: [[0]*350, [1]*5], 2013: [[0]*360], 2014: [[0]*345, [1]*9], 2015: [[0]*10]}\n",
    "        expected_all_no_events1 = {2012: [[1], [9]], 2013: [], 2014: [[15], [1]], 2015: [[356]]}\n",
    "        expected_all_no_events2 = {2012: [[1], [9]], 2013: [], 2014: [[15], [1]], 2015: [[356]]}\n",
    "        expected_durations = [10,5,10,10]\n",
    "        min_events = [10,10,10,10]\n",
    "        # Send inputs to function and then test\n",
    "        all_events1, all_events2, all_no_events1, all_no_events2, durations, min_events = evaluate_EWRs.ctf_calc_sim(EWR_info1, EWR_info2, flows1, flows2, water_years, climates, dates, masked_dates)\n",
    "#         print(all_events1)\n",
    "#         print(expected_all_events1)\n",
    "        for year in all_events1:\n",
    "            self.assertEqual(len(all_events1[year]), len(expected_all_events1[year]))\n",
    "            for i, event in enumerate(all_events1[year]):\n",
    "                self.assertListEqual(event, expected_all_events1[year][i])\n",
    "#         print(all_events2)\n",
    "#         print(expected_all_events2)\n",
    "        for year in all_events2:\n",
    "            self.assertEqual(len(all_events2[year]), len(expected_all_events2[year]))\n",
    "            for i, event in enumerate(all_events2[year]):\n",
    "                self.assertListEqual(event, expected_all_events2[year][i])\n",
    "#         print(all_no_events1)\n",
    "#         print(expected_all_no_events1)\n",
    "        for year in all_no_events1:\n",
    "            self.assertEqual(len(all_no_events1[year]), len(expected_all_no_events1[year]))\n",
    "            for i, no_event in enumerate(all_no_events1[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events1[year][i])\n",
    "#         print(all_no_events2)\n",
    "#         print(expected_all_no_events2)\n",
    "        for year in all_no_events2:\n",
    "            self.assertEqual(len(all_no_events2[year]), len(expected_all_no_events2[year]))\n",
    "            for i, no_event in enumerate(all_no_events2[year]):\n",
    "                self.assertListEqual(no_event, expected_all_no_events2[year][i])\n",
    "        self.assertEqual(durations, expected_durations)\n",
    "\n",
    "        \n",
    "Test = test_evaluate_EWRs()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "suite.addTest(test_evaluate_EWRs('test_component_pull'))\n",
    "suite.addTest(test_evaluate_EWRs('test_apply_correction'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_EWRs'))\n",
    "suite.addTest(test_evaluate_EWRs('test_mask_dates'))\n",
    "suite.addTest(test_evaluate_EWRs('test_wateryear_daily'))\n",
    "suite.addTest(test_evaluate_EWRs('test_which_wateryear'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_duration'))\n",
    "suite.addTest(test_evaluate_EWRs('test_construct_event_dict'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_days_between'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_event_years'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_achievements'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_number_events'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_average_event_length'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_total_days'))\n",
    "suite.addTest(test_evaluate_EWRs('test_get_data_gap'))\n",
    "suite.addTest(test_evaluate_EWRs('test_check_flow'))\n",
    "suite.addTest(test_evaluate_EWRs('test_lowflow_check'))\n",
    "suite.addTest(test_evaluate_EWRs('test_ctf_check'))\n",
    "suite.addTest(test_evaluate_EWRs('test_level_check'))\n",
    "suite.addTest(test_evaluate_EWRs('test_flow_check_sim'))\n",
    "suite.addTest(test_evaluate_EWRs('test_flow_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_lowflow_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_ctf_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_ctf_calc_anytime'))\n",
    "suite.addTest(test_evaluate_EWRs('test_flow_calc_anytime'))\n",
    "suite.addTest(test_evaluate_EWRs('test_lake_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_cumulative_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_cumulative_calc_anytime'))\n",
    "suite.addTest(test_evaluate_EWRs('test_nest_calc_weirpool'))\n",
    "suite.addTest(test_evaluate_EWRs('test_nest_calc_percent'))\n",
    "suite.addTest(test_evaluate_EWRs('test_nest_calc_percent_trigger'))\n",
    "suite.addTest(test_evaluate_EWRs('test_weirpool_calc'))\n",
    "suite.addTest(test_evaluate_EWRs('test_flow_calc_anytime_sim'))\n",
    "suite.addTest(test_evaluate_EWRs('test_flow_calc_sim'))\n",
    "suite.addTest(test_evaluate_EWRs('test_lowflow_calc_sim'))\n",
    "suite.addTest(test_evaluate_EWRs('test_ctf_calc_sim'))\n",
    "\n",
    "\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15fd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
